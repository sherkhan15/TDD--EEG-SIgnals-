{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (8391, 91)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.99694</th>\n",
       "      <th>1.2771</th>\n",
       "      <th>1.29</th>\n",
       "      <th>0.16234</th>\n",
       "      <th>0.21899</th>\n",
       "      <th>0.63294</th>\n",
       "      <th>1.8593</th>\n",
       "      <th>2.4524</th>\n",
       "      <th>0.18744</th>\n",
       "      <th>0.59947</th>\n",
       "      <th>0.76399</th>\n",
       "      <th>2.4999</th>\n",
       "      <th>0.20165</th>\n",
       "      <th>0.64587</th>\n",
       "      <th>2.4696</th>\n",
       "      <th>0.30758</th>\n",
       "      <th>0.0086502</th>\n",
       "      <th>0.75937</th>\n",
       "      <th>0.80735</th>\n",
       "      <th>0.44883</th>\n",
       "      <th>0.2202</th>\n",
       "      <th>0.048213</th>\n",
       "      <th>0.56816</th>\n",
       "      <th>2.22</th>\n",
       "      <th>0.13759</th>\n",
       "      <th>0.22783</th>\n",
       "      <th>2.3247</th>\n",
       "      <th>3.8245</th>\n",
       "      <th>0.16294</th>\n",
       "      <th>0.45981</th>\n",
       "      <th>0.63093</th>\n",
       "      <th>2.5048</th>\n",
       "      <th>0.22467</th>\n",
       "      <th>0.6429</th>\n",
       "      <th>2.6522</th>\n",
       "      <th>1.4054</th>\n",
       "      <th>0.0033433</th>\n",
       "      <th>3.0989</th>\n",
       "      <th>1.9315</th>\n",
       "      <th>0.029908</th>\n",
       "      <th>0.94401</th>\n",
       "      <th>0.31607</th>\n",
       "      <th>0.021917</th>\n",
       "      <th>0.28851</th>\n",
       "      <th>1.4024</th>\n",
       "      <th>1.8474</th>\n",
       "      <th>2.5496</th>\n",
       "      <th>3.3057</th>\n",
       "      <th>0.79513</th>\n",
       "      <th>0.65809</th>\n",
       "      <th>1.124</th>\n",
       "      <th>2.5383</th>\n",
       "      <th>3.4095</th>\n",
       "      <th>0.65106</th>\n",
       "      <th>0.74514</th>\n",
       "      <th>1.1123</th>\n",
       "      <th>3.1651</th>\n",
       "      <th>0.6468</th>\n",
       "      <th>0.87493</th>\n",
       "      <th>3.3942</th>\n",
       "      <th>0.36758</th>\n",
       "      <th>0.057015</th>\n",
       "      <th>0.96547</th>\n",
       "      <th>2.4596</th>\n",
       "      <th>0.50809</th>\n",
       "      <th>0.27792</th>\n",
       "      <th>0.026584</th>\n",
       "      <th>2.5434</th>\n",
       "      <th>9.0592</th>\n",
       "      <th>0.74766</th>\n",
       "      <th>0.8476</th>\n",
       "      <th>2.4937</th>\n",
       "      <th>7.2495</th>\n",
       "      <th>0.6375</th>\n",
       "      <th>0.72856</th>\n",
       "      <th>0.89065</th>\n",
       "      <th>2.8962</th>\n",
       "      <th>0.66011</th>\n",
       "      <th>0.84083</th>\n",
       "      <th>2.9789</th>\n",
       "      <th>2.606</th>\n",
       "      <th>0.065345</th>\n",
       "      <th>1.9741</th>\n",
       "      <th>4.0469</th>\n",
       "      <th>0.077726</th>\n",
       "      <th>1.7905</th>\n",
       "      <th>0.37865</th>\n",
       "      <th>0.055707</th>\n",
       "      <th>0.74315</th>\n",
       "      <th>4.4329</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.18280</td>\n",
       "      <td>1.92420</td>\n",
       "      <td>2.89950</td>\n",
       "      <td>1.13280</td>\n",
       "      <td>1.13810</td>\n",
       "      <td>0.83158</td>\n",
       "      <td>1.47320</td>\n",
       "      <td>2.17720</td>\n",
       "      <td>1.29650</td>\n",
       "      <td>0.87671</td>\n",
       "      <td>0.81847</td>\n",
       "      <td>1.99860</td>\n",
       "      <td>1.26430</td>\n",
       "      <td>1.00850</td>\n",
       "      <td>1.06010</td>\n",
       "      <td>0.14574</td>\n",
       "      <td>0.008549</td>\n",
       "      <td>0.29081</td>\n",
       "      <td>1.09880</td>\n",
       "      <td>0.26210</td>\n",
       "      <td>0.067930</td>\n",
       "      <td>0.011935</td>\n",
       "      <td>0.49663</td>\n",
       "      <td>1.23840</td>\n",
       "      <td>1.16450</td>\n",
       "      <td>1.17330</td>\n",
       "      <td>1.85330</td>\n",
       "      <td>5.24300</td>\n",
       "      <td>1.17210</td>\n",
       "      <td>1.02840</td>\n",
       "      <td>0.90230</td>\n",
       "      <td>1.82280</td>\n",
       "      <td>1.02210</td>\n",
       "      <td>0.85610</td>\n",
       "      <td>1.78340</td>\n",
       "      <td>2.27350</td>\n",
       "      <td>0.028813</td>\n",
       "      <td>0.77116</td>\n",
       "      <td>1.8169</td>\n",
       "      <td>0.022705</td>\n",
       "      <td>0.97292</td>\n",
       "      <td>0.11359</td>\n",
       "      <td>0.011999</td>\n",
       "      <td>0.22265</td>\n",
       "      <td>1.56620</td>\n",
       "      <td>2.4707</td>\n",
       "      <td>3.1008</td>\n",
       "      <td>4.1147</td>\n",
       "      <td>1.09190</td>\n",
       "      <td>0.71181</td>\n",
       "      <td>0.66584</td>\n",
       "      <td>3.5061</td>\n",
       "      <td>3.6547</td>\n",
       "      <td>0.96855</td>\n",
       "      <td>0.39665</td>\n",
       "      <td>0.68786</td>\n",
       "      <td>3.6175</td>\n",
       "      <td>0.67855</td>\n",
       "      <td>0.45030</td>\n",
       "      <td>2.3139</td>\n",
       "      <td>0.39513</td>\n",
       "      <td>0.048856</td>\n",
       "      <td>0.98456</td>\n",
       "      <td>2.3968</td>\n",
       "      <td>0.63283</td>\n",
       "      <td>0.26010</td>\n",
       "      <td>0.083295</td>\n",
       "      <td>2.0970</td>\n",
       "      <td>6.7288</td>\n",
       "      <td>0.87127</td>\n",
       "      <td>0.70234</td>\n",
       "      <td>3.7587</td>\n",
       "      <td>6.4360</td>\n",
       "      <td>0.91468</td>\n",
       "      <td>0.56159</td>\n",
       "      <td>0.62687</td>\n",
       "      <td>3.4086</td>\n",
       "      <td>0.68827</td>\n",
       "      <td>0.52227</td>\n",
       "      <td>3.6962</td>\n",
       "      <td>3.4658</td>\n",
       "      <td>0.086079</td>\n",
       "      <td>1.7638</td>\n",
       "      <td>3.2739</td>\n",
       "      <td>0.095156</td>\n",
       "      <td>1.9786</td>\n",
       "      <td>0.37815</td>\n",
       "      <td>0.049532</td>\n",
       "      <td>0.95852</td>\n",
       "      <td>3.4237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45902</td>\n",
       "      <td>0.63984</td>\n",
       "      <td>0.52790</td>\n",
       "      <td>0.43303</td>\n",
       "      <td>0.32893</td>\n",
       "      <td>0.30588</td>\n",
       "      <td>0.39026</td>\n",
       "      <td>0.64604</td>\n",
       "      <td>0.33423</td>\n",
       "      <td>0.36588</td>\n",
       "      <td>0.45248</td>\n",
       "      <td>0.70728</td>\n",
       "      <td>0.39669</td>\n",
       "      <td>0.34817</td>\n",
       "      <td>1.92130</td>\n",
       "      <td>0.10301</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.92817</td>\n",
       "      <td>1.10570</td>\n",
       "      <td>0.15010</td>\n",
       "      <td>0.090113</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.93769</td>\n",
       "      <td>2.64810</td>\n",
       "      <td>0.30824</td>\n",
       "      <td>0.32064</td>\n",
       "      <td>0.40061</td>\n",
       "      <td>1.83140</td>\n",
       "      <td>0.40939</td>\n",
       "      <td>0.28916</td>\n",
       "      <td>0.28781</td>\n",
       "      <td>0.47195</td>\n",
       "      <td>0.41709</td>\n",
       "      <td>0.34250</td>\n",
       "      <td>0.66613</td>\n",
       "      <td>0.22755</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>1.53380</td>\n",
       "      <td>1.1425</td>\n",
       "      <td>0.071510</td>\n",
       "      <td>1.17730</td>\n",
       "      <td>0.16136</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>0.70938</td>\n",
       "      <td>1.59530</td>\n",
       "      <td>1.6760</td>\n",
       "      <td>2.5235</td>\n",
       "      <td>3.5537</td>\n",
       "      <td>0.58044</td>\n",
       "      <td>0.72842</td>\n",
       "      <td>0.67869</td>\n",
       "      <td>2.6074</td>\n",
       "      <td>4.0847</td>\n",
       "      <td>0.53950</td>\n",
       "      <td>0.58255</td>\n",
       "      <td>0.82586</td>\n",
       "      <td>3.5129</td>\n",
       "      <td>0.58521</td>\n",
       "      <td>0.76858</td>\n",
       "      <td>2.8055</td>\n",
       "      <td>0.41529</td>\n",
       "      <td>0.061982</td>\n",
       "      <td>1.07320</td>\n",
       "      <td>2.8600</td>\n",
       "      <td>0.52941</td>\n",
       "      <td>0.21651</td>\n",
       "      <td>0.050576</td>\n",
       "      <td>2.2548</td>\n",
       "      <td>7.5930</td>\n",
       "      <td>0.60048</td>\n",
       "      <td>0.59570</td>\n",
       "      <td>3.0615</td>\n",
       "      <td>8.9201</td>\n",
       "      <td>0.46166</td>\n",
       "      <td>0.52858</td>\n",
       "      <td>0.69555</td>\n",
       "      <td>3.1139</td>\n",
       "      <td>0.58470</td>\n",
       "      <td>0.75417</td>\n",
       "      <td>3.1051</td>\n",
       "      <td>3.4650</td>\n",
       "      <td>0.046609</td>\n",
       "      <td>1.5890</td>\n",
       "      <td>4.2457</td>\n",
       "      <td>0.052856</td>\n",
       "      <td>2.1995</td>\n",
       "      <td>0.35764</td>\n",
       "      <td>0.078322</td>\n",
       "      <td>1.16530</td>\n",
       "      <td>4.2531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25135</td>\n",
       "      <td>0.18315</td>\n",
       "      <td>0.32631</td>\n",
       "      <td>0.71012</td>\n",
       "      <td>0.81870</td>\n",
       "      <td>0.93663</td>\n",
       "      <td>0.74767</td>\n",
       "      <td>1.03150</td>\n",
       "      <td>0.96265</td>\n",
       "      <td>1.03680</td>\n",
       "      <td>1.04650</td>\n",
       "      <td>0.91701</td>\n",
       "      <td>0.47774</td>\n",
       "      <td>0.92116</td>\n",
       "      <td>1.96730</td>\n",
       "      <td>0.14023</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>0.53291</td>\n",
       "      <td>0.89489</td>\n",
       "      <td>0.36790</td>\n",
       "      <td>0.202050</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.60279</td>\n",
       "      <td>1.31290</td>\n",
       "      <td>0.79119</td>\n",
       "      <td>0.64746</td>\n",
       "      <td>0.58280</td>\n",
       "      <td>0.66389</td>\n",
       "      <td>0.81884</td>\n",
       "      <td>0.85160</td>\n",
       "      <td>0.91678</td>\n",
       "      <td>0.75924</td>\n",
       "      <td>0.65891</td>\n",
       "      <td>1.02550</td>\n",
       "      <td>1.16850</td>\n",
       "      <td>0.40159</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>1.52500</td>\n",
       "      <td>1.9702</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>1.48150</td>\n",
       "      <td>0.19290</td>\n",
       "      <td>0.026342</td>\n",
       "      <td>0.38661</td>\n",
       "      <td>1.17610</td>\n",
       "      <td>3.1808</td>\n",
       "      <td>3.3740</td>\n",
       "      <td>3.2831</td>\n",
       "      <td>0.53835</td>\n",
       "      <td>0.57345</td>\n",
       "      <td>0.89629</td>\n",
       "      <td>2.0811</td>\n",
       "      <td>2.5790</td>\n",
       "      <td>0.39929</td>\n",
       "      <td>0.72357</td>\n",
       "      <td>0.98996</td>\n",
       "      <td>2.4198</td>\n",
       "      <td>0.50281</td>\n",
       "      <td>0.84289</td>\n",
       "      <td>2.7351</td>\n",
       "      <td>0.36873</td>\n",
       "      <td>0.052417</td>\n",
       "      <td>0.82915</td>\n",
       "      <td>2.1863</td>\n",
       "      <td>0.68467</td>\n",
       "      <td>0.42729</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>1.8108</td>\n",
       "      <td>4.3498</td>\n",
       "      <td>0.55221</td>\n",
       "      <td>0.47930</td>\n",
       "      <td>2.1500</td>\n",
       "      <td>5.2714</td>\n",
       "      <td>0.50585</td>\n",
       "      <td>0.69911</td>\n",
       "      <td>1.02750</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.46701</td>\n",
       "      <td>0.94285</td>\n",
       "      <td>2.7683</td>\n",
       "      <td>2.4748</td>\n",
       "      <td>0.071118</td>\n",
       "      <td>1.9235</td>\n",
       "      <td>3.1815</td>\n",
       "      <td>0.079113</td>\n",
       "      <td>1.9122</td>\n",
       "      <td>0.36863</td>\n",
       "      <td>0.037173</td>\n",
       "      <td>1.02140</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.80050</td>\n",
       "      <td>1.06440</td>\n",
       "      <td>1.34030</td>\n",
       "      <td>0.38149</td>\n",
       "      <td>0.34061</td>\n",
       "      <td>0.34281</td>\n",
       "      <td>0.65299</td>\n",
       "      <td>0.94472</td>\n",
       "      <td>0.36371</td>\n",
       "      <td>0.36508</td>\n",
       "      <td>0.35928</td>\n",
       "      <td>1.01510</td>\n",
       "      <td>0.38112</td>\n",
       "      <td>0.42390</td>\n",
       "      <td>0.87211</td>\n",
       "      <td>0.15557</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.41830</td>\n",
       "      <td>1.02800</td>\n",
       "      <td>0.23435</td>\n",
       "      <td>0.135650</td>\n",
       "      <td>0.027006</td>\n",
       "      <td>0.68628</td>\n",
       "      <td>1.39610</td>\n",
       "      <td>0.36923</td>\n",
       "      <td>0.46516</td>\n",
       "      <td>0.87598</td>\n",
       "      <td>3.07020</td>\n",
       "      <td>0.35304</td>\n",
       "      <td>0.34103</td>\n",
       "      <td>0.40550</td>\n",
       "      <td>0.74733</td>\n",
       "      <td>0.34487</td>\n",
       "      <td>0.45965</td>\n",
       "      <td>0.76641</td>\n",
       "      <td>0.67482</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.64233</td>\n",
       "      <td>1.3997</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.96297</td>\n",
       "      <td>0.14542</td>\n",
       "      <td>0.047650</td>\n",
       "      <td>0.51324</td>\n",
       "      <td>1.81600</td>\n",
       "      <td>2.0524</td>\n",
       "      <td>1.7429</td>\n",
       "      <td>2.8583</td>\n",
       "      <td>0.79286</td>\n",
       "      <td>0.76093</td>\n",
       "      <td>1.05520</td>\n",
       "      <td>3.4418</td>\n",
       "      <td>4.5708</td>\n",
       "      <td>0.64689</td>\n",
       "      <td>0.82814</td>\n",
       "      <td>1.07550</td>\n",
       "      <td>4.6703</td>\n",
       "      <td>0.61467</td>\n",
       "      <td>0.90465</td>\n",
       "      <td>4.2928</td>\n",
       "      <td>0.27778</td>\n",
       "      <td>0.063603</td>\n",
       "      <td>1.00640</td>\n",
       "      <td>3.7187</td>\n",
       "      <td>0.47398</td>\n",
       "      <td>0.14641</td>\n",
       "      <td>0.058950</td>\n",
       "      <td>1.9983</td>\n",
       "      <td>5.5227</td>\n",
       "      <td>0.82924</td>\n",
       "      <td>0.70854</td>\n",
       "      <td>3.5484</td>\n",
       "      <td>6.8200</td>\n",
       "      <td>0.74715</td>\n",
       "      <td>0.79799</td>\n",
       "      <td>0.85009</td>\n",
       "      <td>4.0406</td>\n",
       "      <td>0.68466</td>\n",
       "      <td>0.88408</td>\n",
       "      <td>4.1069</td>\n",
       "      <td>3.1452</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>2.6893</td>\n",
       "      <td>6.3835</td>\n",
       "      <td>0.087593</td>\n",
       "      <td>3.3852</td>\n",
       "      <td>0.28269</td>\n",
       "      <td>0.085119</td>\n",
       "      <td>0.56311</td>\n",
       "      <td>3.9294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99437</td>\n",
       "      <td>0.36646</td>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>0.58822</td>\n",
       "      <td>0.67950</td>\n",
       "      <td>1.59060</td>\n",
       "      <td>1.88620</td>\n",
       "      <td>0.31023</td>\n",
       "      <td>0.69369</td>\n",
       "      <td>0.69312</td>\n",
       "      <td>2.07770</td>\n",
       "      <td>0.37823</td>\n",
       "      <td>0.72718</td>\n",
       "      <td>1.23070</td>\n",
       "      <td>0.29847</td>\n",
       "      <td>0.031051</td>\n",
       "      <td>0.66862</td>\n",
       "      <td>1.08450</td>\n",
       "      <td>0.46272</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.018029</td>\n",
       "      <td>0.56068</td>\n",
       "      <td>0.74914</td>\n",
       "      <td>0.43424</td>\n",
       "      <td>0.47597</td>\n",
       "      <td>1.50360</td>\n",
       "      <td>2.73530</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>0.71446</td>\n",
       "      <td>0.57677</td>\n",
       "      <td>1.86690</td>\n",
       "      <td>0.39865</td>\n",
       "      <td>0.73359</td>\n",
       "      <td>2.01420</td>\n",
       "      <td>0.50678</td>\n",
       "      <td>0.021391</td>\n",
       "      <td>1.45460</td>\n",
       "      <td>2.2594</td>\n",
       "      <td>0.033876</td>\n",
       "      <td>1.02010</td>\n",
       "      <td>0.26510</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.52880</td>\n",
       "      <td>0.95201</td>\n",
       "      <td>3.1339</td>\n",
       "      <td>2.8519</td>\n",
       "      <td>2.7088</td>\n",
       "      <td>0.28756</td>\n",
       "      <td>0.55268</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>1.5512</td>\n",
       "      <td>1.6374</td>\n",
       "      <td>0.42841</td>\n",
       "      <td>0.47238</td>\n",
       "      <td>0.73843</td>\n",
       "      <td>1.6289</td>\n",
       "      <td>0.30649</td>\n",
       "      <td>0.55064</td>\n",
       "      <td>1.9040</td>\n",
       "      <td>0.34885</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.86739</td>\n",
       "      <td>1.9546</td>\n",
       "      <td>0.75137</td>\n",
       "      <td>0.28627</td>\n",
       "      <td>0.048138</td>\n",
       "      <td>1.7575</td>\n",
       "      <td>4.2567</td>\n",
       "      <td>0.33753</td>\n",
       "      <td>0.50783</td>\n",
       "      <td>1.7178</td>\n",
       "      <td>3.2145</td>\n",
       "      <td>0.37265</td>\n",
       "      <td>0.60165</td>\n",
       "      <td>0.88183</td>\n",
       "      <td>1.5851</td>\n",
       "      <td>0.47966</td>\n",
       "      <td>0.69495</td>\n",
       "      <td>1.6890</td>\n",
       "      <td>2.0882</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>1.1942</td>\n",
       "      <td>2.0283</td>\n",
       "      <td>0.058093</td>\n",
       "      <td>1.8887</td>\n",
       "      <td>0.38917</td>\n",
       "      <td>0.076706</td>\n",
       "      <td>0.64049</td>\n",
       "      <td>2.3733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.99694   1.2771     1.29  0.16234  0.21899  0.63294   1.8593   2.4524  \\\n",
       "0  1.18280  1.92420  2.89950  1.13280  1.13810  0.83158  1.47320  2.17720   \n",
       "1  0.45902  0.63984  0.52790  0.43303  0.32893  0.30588  0.39026  0.64604   \n",
       "2  0.25135  0.18315  0.32631  0.71012  0.81870  0.93663  0.74767  1.03150   \n",
       "3  1.80050  1.06440  1.34030  0.38149  0.34061  0.34281  0.65299  0.94472   \n",
       "4  0.99437  0.36646  0.49250  0.50493  0.58822  0.67950  1.59060  1.88620   \n",
       "\n",
       "   0.18744  0.59947  0.76399   2.4999  0.20165  0.64587   2.4696  0.30758  \\\n",
       "0  1.29650  0.87671  0.81847  1.99860  1.26430  1.00850  1.06010  0.14574   \n",
       "1  0.33423  0.36588  0.45248  0.70728  0.39669  0.34817  1.92130  0.10301   \n",
       "2  0.96265  1.03680  1.04650  0.91701  0.47774  0.92116  1.96730  0.14023   \n",
       "3  0.36371  0.36508  0.35928  1.01510  0.38112  0.42390  0.87211  0.15557   \n",
       "4  0.31023  0.69369  0.69312  2.07770  0.37823  0.72718  1.23070  0.29847   \n",
       "\n",
       "   0.0086502  0.75937  0.80735  0.44883    0.2202  0.048213  0.56816     2.22  \\\n",
       "0   0.008549  0.29081  1.09880  0.26210  0.067930  0.011935  0.49663  1.23840   \n",
       "1   0.012467  0.92817  1.10570  0.15010  0.090113  0.022224  0.93769  2.64810   \n",
       "2   0.021927  0.53291  0.89489  0.36790  0.202050  0.024962  0.60279  1.31290   \n",
       "3   0.021016  0.41830  1.02800  0.23435  0.135650  0.027006  0.68628  1.39610   \n",
       "4   0.031051  0.66862  1.08450  0.46272  0.122200  0.018029  0.56068  0.74914   \n",
       "\n",
       "   0.13759  0.22783   2.3247   3.8245  0.16294  0.45981  0.63093   2.5048  \\\n",
       "0  1.16450  1.17330  1.85330  5.24300  1.17210  1.02840  0.90230  1.82280   \n",
       "1  0.30824  0.32064  0.40061  1.83140  0.40939  0.28916  0.28781  0.47195   \n",
       "2  0.79119  0.64746  0.58280  0.66389  0.81884  0.85160  0.91678  0.75924   \n",
       "3  0.36923  0.46516  0.87598  3.07020  0.35304  0.34103  0.40550  0.74733   \n",
       "4  0.43424  0.47597  1.50360  2.73530  0.65000  0.71446  0.57677  1.86690   \n",
       "\n",
       "   0.22467   0.6429   2.6522   1.4054  0.0033433   3.0989  1.9315  0.029908  \\\n",
       "0  1.02210  0.85610  1.78340  2.27350   0.028813  0.77116  1.8169  0.022705   \n",
       "1  0.41709  0.34250  0.66613  0.22755   0.004028  1.53380  1.1425  0.071510   \n",
       "2  0.65891  1.02550  1.16850  0.40159   0.011451  1.52500  1.9702  0.028340   \n",
       "3  0.34487  0.45965  0.76641  0.67482   0.005014  0.64233  1.3997  0.017446   \n",
       "4  0.39865  0.73359  2.01420  0.50678   0.021391  1.45460  2.2594  0.033876   \n",
       "\n",
       "   0.94401  0.31607  0.021917  0.28851   1.4024  1.8474  2.5496  3.3057  \\\n",
       "0  0.97292  0.11359  0.011999  0.22265  1.56620  2.4707  3.1008  4.1147   \n",
       "1  1.17730  0.16136  0.028611  0.70938  1.59530  1.6760  2.5235  3.5537   \n",
       "2  1.48150  0.19290  0.026342  0.38661  1.17610  3.1808  3.3740  3.2831   \n",
       "3  0.96297  0.14542  0.047650  0.51324  1.81600  2.0524  1.7429  2.8583   \n",
       "4  1.02010  0.26510  0.013233  0.52880  0.95201  3.1339  2.8519  2.7088   \n",
       "\n",
       "   0.79513  0.65809    1.124  2.5383  3.4095  0.65106  0.74514   1.1123  \\\n",
       "0  1.09190  0.71181  0.66584  3.5061  3.6547  0.96855  0.39665  0.68786   \n",
       "1  0.58044  0.72842  0.67869  2.6074  4.0847  0.53950  0.58255  0.82586   \n",
       "2  0.53835  0.57345  0.89629  2.0811  2.5790  0.39929  0.72357  0.98996   \n",
       "3  0.79286  0.76093  1.05520  3.4418  4.5708  0.64689  0.82814  1.07550   \n",
       "4  0.28756  0.55268  0.69743  1.5512  1.6374  0.42841  0.47238  0.73843   \n",
       "\n",
       "   3.1651   0.6468  0.87493  3.3942  0.36758  0.057015  0.96547  2.4596  \\\n",
       "0  3.6175  0.67855  0.45030  2.3139  0.39513  0.048856  0.98456  2.3968   \n",
       "1  3.5129  0.58521  0.76858  2.8055  0.41529  0.061982  1.07320  2.8600   \n",
       "2  2.4198  0.50281  0.84289  2.7351  0.36873  0.052417  0.82915  2.1863   \n",
       "3  4.6703  0.61467  0.90465  4.2928  0.27778  0.063603  1.00640  3.7187   \n",
       "4  1.6289  0.30649  0.55064  1.9040  0.34885  0.059179  0.86739  1.9546   \n",
       "\n",
       "   0.50809  0.27792  0.026584  2.5434  9.0592  0.74766   0.8476  2.4937  \\\n",
       "0  0.63283  0.26010  0.083295  2.0970  6.7288  0.87127  0.70234  3.7587   \n",
       "1  0.52941  0.21651  0.050576  2.2548  7.5930  0.60048  0.59570  3.0615   \n",
       "2  0.68467  0.42729  0.045990  1.8108  4.3498  0.55221  0.47930  2.1500   \n",
       "3  0.47398  0.14641  0.058950  1.9983  5.5227  0.82924  0.70854  3.5484   \n",
       "4  0.75137  0.28627  0.048138  1.7575  4.2567  0.33753  0.50783  1.7178   \n",
       "\n",
       "   7.2495   0.6375  0.72856  0.89065  2.8962  0.66011  0.84083  2.9789  \\\n",
       "0  6.4360  0.91468  0.56159  0.62687  3.4086  0.68827  0.52227  3.6962   \n",
       "1  8.9201  0.46166  0.52858  0.69555  3.1139  0.58470  0.75417  3.1051   \n",
       "2  5.2714  0.50585  0.69911  1.02750  2.5400  0.46701  0.94285  2.7683   \n",
       "3  6.8200  0.74715  0.79799  0.85009  4.0406  0.68466  0.88408  4.1069   \n",
       "4  3.2145  0.37265  0.60165  0.88183  1.5851  0.47966  0.69495  1.6890   \n",
       "\n",
       "    2.606  0.065345  1.9741  4.0469  0.077726  1.7905  0.37865  0.055707  \\\n",
       "0  3.4658  0.086079  1.7638  3.2739  0.095156  1.9786  0.37815  0.049532   \n",
       "1  3.4650  0.046609  1.5890  4.2457  0.052856  2.1995  0.35764  0.078322   \n",
       "2  2.4748  0.071118  1.9235  3.1815  0.079113  1.9122  0.36863  0.037173   \n",
       "3  3.1452  0.036364  2.6893  6.3835  0.087593  3.3852  0.28269  0.085119   \n",
       "4  2.0882  0.042500  1.1942  2.0283  0.058093  1.8887  0.38917  0.076706   \n",
       "\n",
       "   0.74315  4.4329  1  \n",
       "0  0.95852  3.4237  1  \n",
       "1  1.16530  4.2531  1  \n",
       "2  1.02140  2.9841  1  \n",
       "3  0.56311  3.9294  1  \n",
       "4  0.64049  2.3733  1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df=pd.read_csv('45 channel 1sec alpha-betapower with labels.csv')\n",
    "\n",
    "\n",
    "print('Number of rows and columns:', df.shape)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Labelling COLUMNS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0.99694', '1.2771', '1.29', '0.16234', '0.21899', '0.63294', '1.8593',\n",
      "       '2.4524', '0.18744', '0.59947', '0.76399', '2.4999', '0.20165',\n",
      "       '0.64587', '2.4696', '0.30758', '0.0086502', '0.75937', '0.80735',\n",
      "       '0.44883', '0.2202', '0.048213', '0.56816', '2.22', '0.13759',\n",
      "       '0.22783', '2.3247', '3.8245', '0.16294', '0.45981', '0.63093',\n",
      "       '2.5048', '0.22467', '0.6429', '2.6522', '1.4054', '0.0033433',\n",
      "       '3.0989', '1.9315', '0.029908', '0.94401', '0.31607', '0.021917',\n",
      "       '0.28851', '1.4024', '1.8474', '2.5496', '3.3057', '0.79513', '0.65809',\n",
      "       '1.124', '2.5383', '3.4095', '0.65106', '0.74514', '1.1123', '3.1651',\n",
      "       '0.6468', '0.87493', '3.3942', '0.36758', '0.057015', '0.96547',\n",
      "       '2.4596', '0.50809', '0.27792', '0.026584', '2.5434', '9.0592',\n",
      "       '0.74766', '0.8476', '2.4937', '7.2495', '0.6375', '0.72856', '0.89065',\n",
      "       '2.8962', '0.66011', '0.84083', '2.9789', '2.606', '0.065345', '1.9741',\n",
      "       '4.0469', '0.077726', '1.7905', '0.37865', '0.055707', '0.74315',\n",
      "       '4.4329', '1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {'0.49674':'a', '0.27869':'b', '0.36769':'c', '0.15285':'cd', '0.1606':'d','0.1328':'de','0.17606':'e','0.3842':'f','0.19877':'g',\n",
    "       '0.17507':'l', '0.10564':'m', '0.3156':'n', '0.14643':'o', '0.10827':'p','1.2166':'q', '0.073472':'r',\n",
    "       '0.037876':'s', '0.26714':'t', '0.49989':'u', '0.094403':'v', '0.037798':'w', '0.0073178':'x', '0.6007':'y',\n",
    "       '2.22':'z', '0.13759':'aa', '0.22783':'bb', '2.3247':'cc', '3.8245':'dd', '0.16294':'ee',\n",
    "       '2.7036':'ff', '0.18483':'gg', '0.16376':'hh', '0.13955':'ii', '0.16332':'jj', '0.21231':'kk',\n",
    "       '0.85415':'ll', '0.026382':'mm', '0.47723':'nn', '0.49575':'oo', '0.020878':'pp', '0.56216':'qq',\n",
    "       '0.072675':'rr','0.012301':'j','0.14811':'ss','0.17573':'tt','1.3432':'uu','0.17928':'vv','0.10368':'ww','0.15127':'xx',\n",
    "       '0.20969':'k','0.96803':'h','1':'labels'}\n",
    "df= df.rename(index=str, columns=new_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking any null Values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8391 entries, 0 to 8390\n",
      "Data columns (total 91 columns):\n",
      "0.99694      8391 non-null float64\n",
      "1.2771       8391 non-null float64\n",
      "1.29         8391 non-null float64\n",
      "0.16234      8391 non-null float64\n",
      "0.21899      8391 non-null float64\n",
      "0.63294      8391 non-null float64\n",
      "1.8593       8391 non-null float64\n",
      "2.4524       8391 non-null float64\n",
      "0.18744      8391 non-null float64\n",
      "0.59947      8391 non-null float64\n",
      "0.76399      8391 non-null float64\n",
      "2.4999       8391 non-null float64\n",
      "0.20165      8391 non-null float64\n",
      "0.64587      8391 non-null float64\n",
      "2.4696       8391 non-null float64\n",
      "0.30758      8391 non-null float64\n",
      "0.0086502    8391 non-null float64\n",
      "0.75937      8391 non-null float64\n",
      "0.80735      8391 non-null float64\n",
      "0.44883      8391 non-null float64\n",
      "0.2202       8391 non-null float64\n",
      "0.048213     8391 non-null float64\n",
      "0.56816      8391 non-null float64\n",
      "z            8391 non-null float64\n",
      "aa           8391 non-null float64\n",
      "bb           8391 non-null float64\n",
      "cc           8391 non-null float64\n",
      "dd           8391 non-null float64\n",
      "ee           8391 non-null float64\n",
      "0.45981      8391 non-null float64\n",
      "0.63093      8391 non-null float64\n",
      "2.5048       8391 non-null float64\n",
      "0.22467      8391 non-null float64\n",
      "0.6429       8391 non-null float64\n",
      "2.6522       8391 non-null float64\n",
      "1.4054       8391 non-null float64\n",
      "0.0033433    8391 non-null float64\n",
      "3.0989       8391 non-null float64\n",
      "1.9315       8391 non-null float64\n",
      "0.029908     8391 non-null float64\n",
      "0.94401      8391 non-null float64\n",
      "0.31607      8391 non-null float64\n",
      "0.021917     8391 non-null float64\n",
      "0.28851      8391 non-null float64\n",
      "1.4024       8391 non-null float64\n",
      "1.8474       8391 non-null float64\n",
      "2.5496       8391 non-null float64\n",
      "3.3057       8391 non-null float64\n",
      "0.79513      8391 non-null float64\n",
      "0.65809      8391 non-null float64\n",
      "1.124        8391 non-null float64\n",
      "2.5383       8391 non-null float64\n",
      "3.4095       8391 non-null float64\n",
      "0.65106      8391 non-null float64\n",
      "0.74514      8391 non-null float64\n",
      "1.1123       8391 non-null float64\n",
      "3.1651       8391 non-null float64\n",
      "0.6468       8391 non-null float64\n",
      "0.87493      8391 non-null float64\n",
      "3.3942       8391 non-null float64\n",
      "0.36758      8391 non-null float64\n",
      "0.057015     8391 non-null float64\n",
      "0.96547      8391 non-null float64\n",
      "2.4596       8391 non-null float64\n",
      "0.50809      8391 non-null float64\n",
      "0.27792      8391 non-null float64\n",
      "0.026584     8391 non-null float64\n",
      "2.5434       8391 non-null float64\n",
      "9.0592       8391 non-null float64\n",
      "0.74766      8391 non-null float64\n",
      "0.8476       8391 non-null float64\n",
      "2.4937       8391 non-null float64\n",
      "7.2495       8391 non-null float64\n",
      "0.6375       8391 non-null float64\n",
      "0.72856      8391 non-null float64\n",
      "0.89065      8391 non-null float64\n",
      "2.8962       8391 non-null float64\n",
      "0.66011      8391 non-null float64\n",
      "0.84083      8391 non-null float64\n",
      "2.9789       8391 non-null float64\n",
      "2.606        8391 non-null float64\n",
      "0.065345     8391 non-null float64\n",
      "1.9741       8391 non-null float64\n",
      "4.0469       8391 non-null float64\n",
      "0.077726     8391 non-null float64\n",
      "1.7905       8391 non-null float64\n",
      "0.37865      8391 non-null float64\n",
      "0.055707     8391 non-null float64\n",
      "0.74315      8391 non-null float64\n",
      "4.4329       8391 non-null float64\n",
      "labels       8391 non-null int64\n",
      "dtypes: float64(90), int64(1)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0.99694       1.2771         1.29      0.16234      0.21899  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.680212     4.266713     4.358381     9.996456     6.295796   \n",
      "std       6.823723     6.222283     5.658669    13.960113     9.518230   \n",
      "min       0.082963     0.122500     0.088702     0.048642     0.052602   \n",
      "25%       1.349850     1.238600     1.513100     2.677600     1.640950   \n",
      "50%       2.557800     2.266000     2.703100     5.647600     3.423300   \n",
      "75%       5.258750     4.585100     5.087350    11.642500     7.155000   \n",
      "max     113.930000    78.915000   148.430000   213.700000   197.330000   \n",
      "\n",
      "           0.63294       1.8593       2.4524      0.18744      0.59947  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      6.869423     6.545154     8.302750     8.473059     5.647723   \n",
      "std      10.746785    10.680664     9.936116    12.677910     8.453658   \n",
      "min       0.071089     0.171790     0.197540     0.045078     0.043657   \n",
      "25%       1.580800     1.979700     2.766850     2.154200     1.428350   \n",
      "50%       3.417800     3.768700     5.282500     4.432000     3.032200   \n",
      "75%       7.505450     7.483600     9.854150     9.400950     6.462700   \n",
      "max     163.560000   580.600000   166.120000   204.940000   152.760000   \n",
      "\n",
      "           0.76399       2.4999      0.20165      0.64587       2.4696  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.277797     8.568798     6.371385     2.917829     6.425101   \n",
      "std       7.896445    13.893190     9.225498     4.627195     9.883636   \n",
      "min       0.075203     0.174300     0.055157     0.003892     0.102060   \n",
      "25%       1.507000     2.256100     1.599400     0.686800     1.591550   \n",
      "50%       2.885900     4.317700     3.364600     1.439900     3.123100   \n",
      "75%       5.896450     8.790450     7.330300     3.352250     6.890800   \n",
      "max     198.170000   292.190000   149.800000   194.880000   186.410000   \n",
      "\n",
      "           0.30758    0.0086502      0.75937      0.80735      0.44883  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      9.182758     1.822529     1.900849     8.901547    12.848909   \n",
      "std      14.108669     2.649852     8.705053    17.468620    23.156923   \n",
      "min       0.024003     0.001719     0.002452     0.176620     0.040149   \n",
      "25%       2.432850     0.514140     0.377370     2.257400     3.546650   \n",
      "50%       4.816400     1.040800     0.812500     4.104800     6.716100   \n",
      "75%      10.241000     2.198800     1.914750     8.254000    13.530500   \n",
      "max     277.040000   130.950000   748.970000   338.500000   525.010000   \n",
      "\n",
      "            0.2202     0.048213      0.56816            z           aa  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.184149     2.072978     5.822868    11.620797     6.120768   \n",
      "std       7.488946     3.692738    12.205158    19.118401     7.964228   \n",
      "min       0.019364     0.002186     0.016792     0.052182     0.059154   \n",
      "25%       1.429800     0.457800     1.577000     3.503800     1.913400   \n",
      "50%       2.879200     1.118800     3.118800     6.639200     3.747200   \n",
      "75%       5.950550     2.274750     6.438850    12.287500     7.172900   \n",
      "max     131.110000   160.900000   794.740000   410.130000   137.710000   \n",
      "\n",
      "                bb           cc           dd           ee      0.45981  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.124055     4.799556     5.943196     6.447796     5.947976   \n",
      "std       8.225643     6.826754     6.243750     9.730075     9.292132   \n",
      "min       0.024389     0.042428     0.121950     0.038725     0.060799   \n",
      "25%       1.183150     1.467250     2.321550     1.592250     1.517450   \n",
      "50%       2.550700     2.753500     4.164100     3.538900     3.195600   \n",
      "75%       5.715400     5.424700     7.427000     7.507250     6.735450   \n",
      "max     142.740000   156.270000   155.880000   161.890000   193.510000   \n",
      "\n",
      "           0.63093       2.5048      0.22467       0.6429       2.6522  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.754505     6.894343     7.038629     6.566679     6.454629   \n",
      "std       8.307750     9.783904    10.162022    19.639854     9.607925   \n",
      "min       0.053798     0.178660     0.053151     0.048530     0.109270   \n",
      "25%       1.593900     2.011000     1.725500     1.536700     1.647000   \n",
      "50%       3.245500     3.902400     3.777400     3.416600     3.218400   \n",
      "75%       6.482400     7.718450     8.351800     7.509450     7.025250   \n",
      "max     159.990000   175.450000   217.440000  1587.700000   190.190000   \n",
      "\n",
      "            1.4054    0.0033433       3.0989       1.9315     0.029908  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      9.003484     3.498434     4.048647     9.097580     4.358885   \n",
      "std      13.521627     4.911708     7.341300    14.622292     6.707393   \n",
      "min       0.110860     0.001304     0.029234     0.077371     0.003185   \n",
      "25%       2.190300     0.833705     0.758680     2.361500     0.912245   \n",
      "50%       4.535900     1.900900     1.672600     4.579900     2.078600   \n",
      "75%       9.982100     4.198200     4.077400     9.790500     5.014750   \n",
      "max     243.920000   152.510000   187.770000   258.300000   139.410000   \n",
      "\n",
      "           0.94401      0.31607     0.021917      0.28851       1.4024  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.588745     9.002957     4.212775     3.345934     9.212848   \n",
      "std      10.711398    15.240102     5.540549     4.675819    19.409590   \n",
      "min       0.034208     0.028003     0.003282     0.006439     0.029835   \n",
      "25%       1.060000     2.557850     1.144750     0.932260     2.031750   \n",
      "50%       2.275800     5.026300     2.513300     1.999600     4.353600   \n",
      "75%       4.926400     9.732050     5.119600     4.117750     8.558500   \n",
      "max     743.230000   386.420000   129.170000   157.310000   322.000000   \n",
      "\n",
      "            1.8474       2.5496       3.3057      0.79513      0.65809  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.229256     4.581593     5.113527    11.637879     5.828835   \n",
      "std       5.455699     5.227413     5.554233    27.871367     7.628745   \n",
      "min       0.488380     0.165730     0.435770     0.216740     0.197270   \n",
      "25%       2.487700     1.885600     2.488900     3.288450     2.137500   \n",
      "50%       3.754900     3.088600     3.760900     6.755200     3.615200   \n",
      "75%       5.965750     5.335400     6.005500    11.739000     6.450550   \n",
      "max     114.150000   182.100000   170.890000  1195.000000   246.470000   \n",
      "\n",
      "             1.124       2.5383       3.4095      0.65106      0.74514  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.131929     6.722141    12.008532    10.589621     4.569252   \n",
      "std       6.133803    13.013718    48.352535    29.672747     5.511620   \n",
      "min       0.231350     0.483770     0.802540     0.192770     0.165800   \n",
      "25%       1.820500     2.627250     3.945650     2.590850     1.832350   \n",
      "50%       3.207800     4.027500     6.534400     5.005800     2.974300   \n",
      "75%       5.783400     6.648350    11.093000     9.520150     4.850550   \n",
      "max     126.680000   449.410000  2451.300000  1383.000000   126.450000   \n",
      "\n",
      "            1.1123       3.1651       0.6468      0.87493       3.3942  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.503047    10.709194     5.874474     2.346234     5.524527   \n",
      "std       6.015477    27.749195    13.241138     3.836986    11.903354   \n",
      "min       0.296400     0.717880     0.205490     0.019583     0.208650   \n",
      "25%       1.790200     3.029650     1.934000     0.809420     2.040650   \n",
      "50%       2.857600     5.014500     3.246900     1.324100     3.295700   \n",
      "75%       4.723150     8.898800     5.993700     2.450200     5.882200   \n",
      "max     180.400000  1328.900000   569.760000   144.920000   534.410000   \n",
      "\n",
      "           0.36758     0.057015      0.96547       2.4596      0.50809  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      7.748295     1.652208     1.589141     7.225124     9.609517   \n",
      "std      11.101463     3.027635     7.360296    11.512498     9.986518   \n",
      "min       0.149520     0.017924     0.018404     0.535760     0.215020   \n",
      "25%       3.016450     0.619185     0.540220     2.782100     3.666450   \n",
      "50%       4.754200     0.982070     0.873580     4.337200     6.701100   \n",
      "75%       8.264000     1.658300     1.504700     7.629750    12.535000   \n",
      "max     343.230000   132.540000   639.990000   285.610000   347.060000   \n",
      "\n",
      "           0.27792     0.026584       2.5434       9.0592     0.74766  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.00000   \n",
      "mean      3.367419     1.431923     3.745933     8.878795     7.14773   \n",
      "std       3.017629     2.062826     7.577369     8.673383    16.48962   \n",
      "min       0.085031     0.012885     0.071494     0.179040     0.22693   \n",
      "25%       1.750550     0.621535     1.808950     4.440900     3.06740   \n",
      "50%       2.774200     1.097100     2.989900     7.319700     4.94310   \n",
      "75%       4.147550     1.751650     4.766500    11.310500     8.17010   \n",
      "max     133.170000   142.790000   633.730000   404.330000  1043.30000   \n",
      "\n",
      "            0.8476       2.4937       7.2495       0.6375      0.72856  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.975331     5.071719     7.818976     7.515197     5.157684   \n",
      "std       6.645237     6.868668    12.728261    14.878358     6.629362   \n",
      "min       0.157100     0.309260     0.431030     0.128700     0.287050   \n",
      "25%       1.655950     2.148200     3.473950     2.224150     1.839750   \n",
      "50%       2.910400     3.394600     5.432500     4.177900     3.070600   \n",
      "75%       5.602650     5.603550     8.617050     7.851600     5.397850   \n",
      "max     128.000000   187.780000   458.050000   735.030000   111.550000   \n",
      "\n",
      "           0.89065       2.8962      0.66011      0.84083       2.9789  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.925688     8.081620     7.474088     5.372810     6.452662   \n",
      "std       6.181697    15.649229    14.994489    12.334634    26.310679   \n",
      "min       0.250740     0.561420     0.216120     0.182050     0.304390   \n",
      "25%       1.904150     2.821150     2.233850     1.826050     2.147100   \n",
      "50%       3.197400     4.579100     3.949300     3.138100     3.606300   \n",
      "75%       5.504400     8.122400     7.721450     5.798850     6.146650   \n",
      "max     126.680000   467.240000   659.610000   952.200000  1360.300000   \n",
      "\n",
      "             2.606     0.065345       1.9741       4.0469     0.077726  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      8.305620     2.968062     3.317029     9.483537     3.355093   \n",
      "std      15.268513     6.229057     8.943329    19.697778     6.951205   \n",
      "min       0.342240     0.021608     0.122970     0.539790     0.034707   \n",
      "25%       2.873450     1.029000     0.913385     3.207200     1.209500   \n",
      "50%       5.079800     1.739400     1.627800     5.360100     2.087000   \n",
      "75%       9.169350     2.999250     3.196850     9.556850     3.689950   \n",
      "max     769.080000   379.490000   601.620000   995.720000   464.880000   \n",
      "\n",
      "            1.7905      0.37865     0.055707      0.74315       4.4329  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      3.430963     5.775767     2.789094     2.451646     5.613311   \n",
      "std       8.147337     5.267075     2.727323     2.647392     5.150284   \n",
      "min       0.072909     0.155330     0.025637     0.041080     0.114590   \n",
      "25%       1.435550     2.792400     1.335550     1.054800     2.556600   \n",
      "50%       2.407200     4.464800     2.223100     1.866600     4.271100   \n",
      "75%       3.919100     7.307450     3.505200     3.150200     7.147300   \n",
      "max     635.060000   140.940000   132.240000   151.400000   168.840000   \n",
      "\n",
      "            labels  \n",
      "count  8391.000000  \n",
      "mean      0.424383  \n",
      "std       0.494278  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       1.000000  \n",
      "max       1.000000  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***spliting the file in the data and target class***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:,:-1].values.tolist()\n",
    "target = df.iloc[:,-1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x =df[df.columns[:98]]\n",
    "y =df.labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state =  90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Select numerical columns which needs to be normalized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = x_train[x_train.columns[0:20]]\n",
    "test_norm = x_test[x_test.columns[0:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(train_norm)\n",
    "x_train_norm = std_scale.transform(train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting numpy array to dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.99694    1.2771      1.29   0.16234   0.21899   0.63294    1.8593  \\\n",
      "1585 -0.574809 -0.478664 -0.259870 -0.628864 -0.154049 -0.297376 -0.662377   \n",
      "992   1.025842  3.236589  1.417560  1.757329  0.675966  3.868469  0.696159   \n",
      "8204 -0.576262 -0.397916 -0.196709  0.137886 -0.135022  0.242636  0.167129   \n",
      "4674 -0.373001 -0.512045 -0.423963 -0.412675 -0.327287 -0.311574 -0.328459   \n",
      "3593 -0.346911 -0.239245 -0.323992  0.013752 -0.343723 -0.007083  0.614490   \n",
      "\n",
      "        2.4524   0.18744   0.59947   0.76399    2.4999   0.20165   0.64587  \\\n",
      "1585 -0.750731 -0.316596  0.262810 -0.513902 -0.572479 -0.178767 -0.228254   \n",
      "992   3.211227 -0.373047  0.569718 -0.160057 -0.452776  1.258622 -0.032740   \n",
      "8204  0.278209  0.214960  0.295363  0.489236 -0.040465 -0.084042  0.389735   \n",
      "4674 -0.636181 -0.603127 -0.435563 -0.216817 -0.277460 -0.142008 -0.442595   \n",
      "3593 -0.053239 -0.282781 -0.414003  0.280569  0.043290 -0.332850 -0.125269   \n",
      "\n",
      "        2.4696   0.30758  0.0086502   0.75937   0.80735   0.44883  0.2202  \\\n",
      "1585 -0.369962 -0.530684  -0.367454 -0.048612 -0.395704 -0.426842  1.2677   \n",
      "992  -0.380410  0.099898  -0.128734  0.325282  0.371028 -0.163152  5.1223   \n",
      "8204  1.556137  1.782528   0.165806  0.843727  2.277344  0.210822  9.3477   \n",
      "4674  0.386778 -0.460914   0.728454  0.073673 -0.203789 -0.522872  3.8100   \n",
      "3593  0.318598 -0.340496  -0.242504 -0.142303 -0.300703 -0.228802  3.4216   \n",
      "\n",
      "      0.048213  0.56816        z        aa       bb       cc       dd      ee  \\\n",
      "1585   2.66520   4.5598   7.4755   0.90291   2.4814  0.87988   1.0507  3.0642   \n",
      "992    6.91980  13.3770   4.5502  12.63500  22.1720  2.98920  19.0040  2.7304   \n",
      "8204   1.12080  14.8130  22.5770   3.86180   5.0099  6.29550   7.5109  3.9399   \n",
      "4674   0.81793   2.9421   4.8181   3.41890   1.2427  2.84990   5.5722  4.5349   \n",
      "3593   1.26790   1.7081   6.6163   5.60750   4.1069  8.21940   4.0425  5.8979   \n",
      "\n",
      "      0.45981  0.63093    2.5048  0.22467   0.6429   2.6522   1.4054  \\\n",
      "1585   5.5381   3.2306   0.91077   8.2316   3.1882  0.99948   2.3103   \n",
      "992    4.2847   4.1959  17.96500  11.0260  10.7050  1.27120   3.2647   \n",
      "8204   4.9044   9.7053   8.15790   5.3447   9.4798  6.63220  29.2710   \n",
      "4674   2.9519   3.0385   5.89470   1.0269   3.2377  4.19660   1.7666   \n",
      "3593   3.3224   9.7416  11.23400   1.6252   7.4624  9.75610   3.3173   \n",
      "\n",
      "      0.0033433   3.0989   1.9315  0.029908  0.94401  0.31607  0.021917  \\\n",
      "1585    2.94610   1.2151   2.7254   1.98710   2.2612   2.7194    1.4597   \n",
      "992    20.51800  23.4950  11.4360   0.59974   1.2247  21.2440   12.5060   \n",
      "8204    3.66160   9.4356  36.4680  16.30400  40.0890   8.6478    8.3113   \n",
      "4674    2.20100   4.2802   9.4173   7.36950   8.9857   3.7818    4.1858   \n",
      "3593    0.77452   5.0175   6.2512   4.50580   4.4697   9.2038    4.0098   \n",
      "\n",
      "      0.28851    1.4024   1.8474    2.5496  3.3057  0.79513  0.65809   1.124  \\\n",
      "1585   4.0352   3.28450   1.3447   1.12150  2.0448   6.7579   1.9337  2.3032   \n",
      "992    4.0373   0.83574  11.2410  11.37300  6.8861   6.6774   6.6623  6.4097   \n",
      "8204   5.7913  24.01500   3.5051   1.64080  1.3470   9.2991   3.7227  4.2942   \n",
      "4674   1.4933   4.50750   1.1464   0.86164  3.4981   2.5004   2.2391  3.2879   \n",
      "3593   2.0353   3.55010   2.3286   1.83100  1.4820   9.6551   4.6695  4.5021   \n",
      "\n",
      "      2.5383  3.4095  0.65106  0.74514  1.1123   3.1651  0.6468  0.87493  \\\n",
      "1585  1.5624  1.5557   3.6550   2.1096  2.2260   1.5850  3.5693  0.91562   \n",
      "992   7.2287  6.4962   7.2356   9.6993  6.5243   6.1128  8.2796  5.59480   \n",
      "8204  5.4157  5.1435   5.5314   4.3302  3.4973   5.5237  3.9554  1.59070   \n",
      "4674  7.0275  8.2897   2.0235   2.2761  2.7753  14.9980  1.5267  0.91572   \n",
      "3593  4.1277  9.4608   9.2453   5.0012  3.3514   4.3541  8.1042  1.13240   \n",
      "\n",
      "      3.3942  0.36758  0.057015  0.96547   2.4596  0.50809  0.27792  0.026584  \\\n",
      "1585  1.9315   3.4353   0.48811  0.59280   2.7703   3.6673  0.44351   1.08450   \n",
      "992   6.3806   7.0243   2.39710  2.49810   5.5937   6.1342  3.19470   2.43770   \n",
      "8204  6.1378   2.9356   0.73472  0.77688   2.6518   2.5323  1.49820   0.42358   \n",
      "4674  2.8629   2.1865   0.88627  0.53673  10.7900   4.4343  1.38760   1.50890   \n",
      "3593  3.3736   6.4749   0.95858  0.46532   3.3331  10.0490  1.93920   1.20800   \n",
      "\n",
      "      2.5434  9.0592  0.74766   0.8476  2.4937  7.2495  0.6375  0.72856  \\\n",
      "1585  2.6379  5.1807   2.0880   1.8348  1.6220  1.8534  7.4828   2.6757   \n",
      "992   4.1316  1.7157   8.8349  11.1060  6.0024  8.4009  6.3916   6.7306   \n",
      "8204  1.6594  5.3257   4.7446   4.9794  4.9472  3.3693  4.1825   3.6948   \n",
      "4674  1.6841  3.5594   1.3949   1.2639  5.8352  8.7573  2.3154   2.6560   \n",
      "3593  1.9177  5.0406   5.2958   3.5179  2.4645  4.7319  6.0500   4.4628   \n",
      "\n",
      "      0.89065   2.8962  0.66011  0.84083  2.9789   2.606  0.065345    1.9741  \\\n",
      "1585   2.3059   1.8871   2.7727   2.9249  1.6384  8.1130   1.35920   0.76051   \n",
      "992    7.0949   8.1775  10.3730  10.6630  2.8465  2.4838   6.45490  10.24300   \n",
      "8204   4.6589   5.2471   4.2341   3.6483  6.0214  4.5472   1.89050   3.44380   \n",
      "4674   4.3202  11.7580   1.8353   2.1723  4.6194  2.7669   0.89815   0.94710   \n",
      "3593   4.6774   3.5322   6.7474   3.5360  2.9662  9.3998   3.23060   1.41850   \n",
      "\n",
      "       4.0469  0.077726   1.7905  0.37865  0.055707  0.74315   4.4329  labels  \n",
      "1585   5.7085   2.41040  1.45570   1.8148   0.63196   1.5633  3.12430       1  \n",
      "992    6.7296   0.42437  0.69708   6.4759   6.97100   1.6826  0.52417       1  \n",
      "8204   3.3420   2.18860  2.20380   1.4239   1.57270   0.7503  2.82600       1  \n",
      "4674  16.0500   1.21940  1.62540   1.5423   1.52060   1.0707  4.18850       1  \n",
      "3593   3.3889   4.13550  1.13950   6.0627   2.33170   2.2049  3.15250       1  \n"
     ]
    }
   ],
   "source": [
    "training_norm_col = pd.DataFrame(x_train_norm, index=train_norm.index, columns=train_norm.columns) \n",
    "x_train.update(training_norm_col)\n",
    "print (x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize Testing Data by using mean and SD of training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.99694    1.2771      1.29   0.16234   0.21899   0.63294    1.8593  \\\n",
      "1585 -0.574809 -0.478664 -0.259870 -0.628864 -0.154049 -0.297376 -0.662377   \n",
      "992   1.025842  3.236589  1.417560  1.757329  0.675966  3.868469  0.696159   \n",
      "8204 -0.576262 -0.397916 -0.196709  0.137886 -0.135022  0.242636  0.167129   \n",
      "4674 -0.373001 -0.512045 -0.423963 -0.412675 -0.327287 -0.311574 -0.328459   \n",
      "3593 -0.346911 -0.239245 -0.323992  0.013752 -0.343723 -0.007083  0.614490   \n",
      "\n",
      "        2.4524   0.18744   0.59947   0.76399    2.4999   0.20165   0.64587  \\\n",
      "1585 -0.750731 -0.316596  0.262810 -0.513902 -0.572479 -0.178767 -0.228254   \n",
      "992   3.211227 -0.373047  0.569718 -0.160057 -0.452776  1.258622 -0.032740   \n",
      "8204  0.278209  0.214960  0.295363  0.489236 -0.040465 -0.084042  0.389735   \n",
      "4674 -0.636181 -0.603127 -0.435563 -0.216817 -0.277460 -0.142008 -0.442595   \n",
      "3593 -0.053239 -0.282781 -0.414003  0.280569  0.043290 -0.332850 -0.125269   \n",
      "\n",
      "        2.4696   0.30758  0.0086502   0.75937   0.80735   0.44883  0.2202  \\\n",
      "1585 -0.369962 -0.530684  -0.367454 -0.048612 -0.395704 -0.426842  1.2677   \n",
      "992  -0.380410  0.099898  -0.128734  0.325282  0.371028 -0.163152  5.1223   \n",
      "8204  1.556137  1.782528   0.165806  0.843727  2.277344  0.210822  9.3477   \n",
      "4674  0.386778 -0.460914   0.728454  0.073673 -0.203789 -0.522872  3.8100   \n",
      "3593  0.318598 -0.340496  -0.242504 -0.142303 -0.300703 -0.228802  3.4216   \n",
      "\n",
      "      0.048213  0.56816        z        aa       bb       cc       dd      ee  \\\n",
      "1585   2.66520   4.5598   7.4755   0.90291   2.4814  0.87988   1.0507  3.0642   \n",
      "992    6.91980  13.3770   4.5502  12.63500  22.1720  2.98920  19.0040  2.7304   \n",
      "8204   1.12080  14.8130  22.5770   3.86180   5.0099  6.29550   7.5109  3.9399   \n",
      "4674   0.81793   2.9421   4.8181   3.41890   1.2427  2.84990   5.5722  4.5349   \n",
      "3593   1.26790   1.7081   6.6163   5.60750   4.1069  8.21940   4.0425  5.8979   \n",
      "\n",
      "      0.45981  0.63093    2.5048  0.22467   0.6429   2.6522   1.4054  \\\n",
      "1585   5.5381   3.2306   0.91077   8.2316   3.1882  0.99948   2.3103   \n",
      "992    4.2847   4.1959  17.96500  11.0260  10.7050  1.27120   3.2647   \n",
      "8204   4.9044   9.7053   8.15790   5.3447   9.4798  6.63220  29.2710   \n",
      "4674   2.9519   3.0385   5.89470   1.0269   3.2377  4.19660   1.7666   \n",
      "3593   3.3224   9.7416  11.23400   1.6252   7.4624  9.75610   3.3173   \n",
      "\n",
      "      0.0033433   3.0989   1.9315  0.029908  0.94401  0.31607  0.021917  \\\n",
      "1585    2.94610   1.2151   2.7254   1.98710   2.2612   2.7194    1.4597   \n",
      "992    20.51800  23.4950  11.4360   0.59974   1.2247  21.2440   12.5060   \n",
      "8204    3.66160   9.4356  36.4680  16.30400  40.0890   8.6478    8.3113   \n",
      "4674    2.20100   4.2802   9.4173   7.36950   8.9857   3.7818    4.1858   \n",
      "3593    0.77452   5.0175   6.2512   4.50580   4.4697   9.2038    4.0098   \n",
      "\n",
      "      0.28851    1.4024   1.8474    2.5496  3.3057  0.79513  0.65809   1.124  \\\n",
      "1585   4.0352   3.28450   1.3447   1.12150  2.0448   6.7579   1.9337  2.3032   \n",
      "992    4.0373   0.83574  11.2410  11.37300  6.8861   6.6774   6.6623  6.4097   \n",
      "8204   5.7913  24.01500   3.5051   1.64080  1.3470   9.2991   3.7227  4.2942   \n",
      "4674   1.4933   4.50750   1.1464   0.86164  3.4981   2.5004   2.2391  3.2879   \n",
      "3593   2.0353   3.55010   2.3286   1.83100  1.4820   9.6551   4.6695  4.5021   \n",
      "\n",
      "      2.5383  3.4095  0.65106  0.74514  1.1123   3.1651  0.6468  0.87493  \\\n",
      "1585  1.5624  1.5557   3.6550   2.1096  2.2260   1.5850  3.5693  0.91562   \n",
      "992   7.2287  6.4962   7.2356   9.6993  6.5243   6.1128  8.2796  5.59480   \n",
      "8204  5.4157  5.1435   5.5314   4.3302  3.4973   5.5237  3.9554  1.59070   \n",
      "4674  7.0275  8.2897   2.0235   2.2761  2.7753  14.9980  1.5267  0.91572   \n",
      "3593  4.1277  9.4608   9.2453   5.0012  3.3514   4.3541  8.1042  1.13240   \n",
      "\n",
      "      3.3942  0.36758  0.057015  0.96547   2.4596  0.50809  0.27792  0.026584  \\\n",
      "1585  1.9315   3.4353   0.48811  0.59280   2.7703   3.6673  0.44351   1.08450   \n",
      "992   6.3806   7.0243   2.39710  2.49810   5.5937   6.1342  3.19470   2.43770   \n",
      "8204  6.1378   2.9356   0.73472  0.77688   2.6518   2.5323  1.49820   0.42358   \n",
      "4674  2.8629   2.1865   0.88627  0.53673  10.7900   4.4343  1.38760   1.50890   \n",
      "3593  3.3736   6.4749   0.95858  0.46532   3.3331  10.0490  1.93920   1.20800   \n",
      "\n",
      "      2.5434  9.0592  0.74766   0.8476  2.4937  7.2495  0.6375  0.72856  \\\n",
      "1585  2.6379  5.1807   2.0880   1.8348  1.6220  1.8534  7.4828   2.6757   \n",
      "992   4.1316  1.7157   8.8349  11.1060  6.0024  8.4009  6.3916   6.7306   \n",
      "8204  1.6594  5.3257   4.7446   4.9794  4.9472  3.3693  4.1825   3.6948   \n",
      "4674  1.6841  3.5594   1.3949   1.2639  5.8352  8.7573  2.3154   2.6560   \n",
      "3593  1.9177  5.0406   5.2958   3.5179  2.4645  4.7319  6.0500   4.4628   \n",
      "\n",
      "      0.89065   2.8962  0.66011  0.84083  2.9789   2.606  0.065345    1.9741  \\\n",
      "1585   2.3059   1.8871   2.7727   2.9249  1.6384  8.1130   1.35920   0.76051   \n",
      "992    7.0949   8.1775  10.3730  10.6630  2.8465  2.4838   6.45490  10.24300   \n",
      "8204   4.6589   5.2471   4.2341   3.6483  6.0214  4.5472   1.89050   3.44380   \n",
      "4674   4.3202  11.7580   1.8353   2.1723  4.6194  2.7669   0.89815   0.94710   \n",
      "3593   4.6774   3.5322   6.7474   3.5360  2.9662  9.3998   3.23060   1.41850   \n",
      "\n",
      "       4.0469  0.077726   1.7905  0.37865  0.055707  0.74315   4.4329  labels  \n",
      "1585   5.7085   2.41040  1.45570   1.8148   0.63196   1.5633  3.12430       1  \n",
      "992    6.7296   0.42437  0.69708   6.4759   6.97100   1.6826  0.52417       1  \n",
      "8204   3.3420   2.18860  2.20380   1.4239   1.57270   0.7503  2.82600       1  \n",
      "4674  16.0500   1.21940  1.62540   1.5423   1.52060   1.0707  4.18850       1  \n",
      "3593   3.3889   4.13550  1.13950   6.0627   2.33170   2.2049  3.15250       1  \n"
     ]
    }
   ],
   "source": [
    "x_test_norm = std_scale.transform(test_norm)\n",
    "testing_norm_col = pd.DataFrame(x_test_norm, index=test_norm.index, columns=test_norm.columns) \n",
    "x_test.update(testing_norm_col)\n",
    "print (x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support vector machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2784  135]\n",
      " [1944  172]]\n",
      "Accuracy score : \n",
      "58.7090367428004\n"
     ]
    }
   ],
   "source": [
    "def svm_classifier(): \n",
    "    file_x = '45 channel 1sec alpha-betapower.csv'\n",
    "    file_y = 'Label.csv'\n",
    "    \n",
    "    X = data\n",
    "    y = target\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=42)\n",
    "   \n",
    "    \t\n",
    "\n",
    "     # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)    \n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # SVM Classifier\n",
    "    clf = SVC(kernel = 'rbf', random_state = 50)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    print(cm)\n",
    "    print(\"Accuracy score : \")\n",
    "    print(accuracy_score(y_test, y_predict)*100)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    svm_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5873/5873 [==============================] - 1s 198us/step - loss: 1.2457 - acc: 0.5130\n",
      "Epoch 2/25\n",
      "5873/5873 [==============================] - 1s 88us/step - loss: 0.8754 - acc: 0.5256\n",
      "Epoch 3/25\n",
      "5873/5873 [==============================] - 0s 70us/step - loss: 0.7901 - acc: 0.5518\n",
      "Epoch 4/25\n",
      "5873/5873 [==============================] - 0s 67us/step - loss: 0.7419 - acc: 0.5629: 0s - loss: 0.7444 - acc: 0.560\n",
      "Epoch 5/25\n",
      "5873/5873 [==============================] - 0s 44us/step - loss: 0.7343 - acc: 0.5728\n",
      "Epoch 6/25\n",
      "5873/5873 [==============================] - 1s 92us/step - loss: 0.7203 - acc: 0.5782\n",
      "Epoch 7/25\n",
      "5873/5873 [==============================] - 0s 70us/step - loss: 0.7091 - acc: 0.5825\n",
      "Epoch 8/25\n",
      "5873/5873 [==============================] - 0s 44us/step - loss: 0.7068 - acc: 0.5856\n",
      "Epoch 9/25\n",
      "5873/5873 [==============================] - 0s 64us/step - loss: 0.7039 - acc: 0.5917\n",
      "Epoch 10/25\n",
      "5873/5873 [==============================] - 0s 62us/step - loss: 0.6949 - acc: 0.5907\n",
      "Epoch 11/25\n",
      "5873/5873 [==============================] - 0s 65us/step - loss: 0.6944 - acc: 0.5951\n",
      "Epoch 12/25\n",
      "5873/5873 [==============================] - 0s 84us/step - loss: 0.6905 - acc: 0.5994: 0s - loss: 0.6941 - acc\n",
      "Epoch 13/25\n",
      "5873/5873 [==============================] - 0s 67us/step - loss: 0.6716 - acc: 0.6148\n",
      "Epoch 14/25\n",
      "5873/5873 [==============================] - 0s 52us/step - loss: 0.6680 - acc: 0.6155\n",
      "Epoch 15/25\n",
      "5873/5873 [==============================] - 0s 65us/step - loss: 0.6675 - acc: 0.6310\n",
      "Epoch 16/25\n",
      "5873/5873 [==============================] - 1s 89us/step - loss: 0.6610 - acc: 0.6302\n",
      "Epoch 17/25\n",
      "5873/5873 [==============================] - 0s 73us/step - loss: 0.6538 - acc: 0.6419\n",
      "Epoch 18/25\n",
      "5873/5873 [==============================] - 0s 51us/step - loss: 0.6440 - acc: 0.6523\n",
      "Epoch 19/25\n",
      "5873/5873 [==============================] - 0s 66us/step - loss: 0.6313 - acc: 0.6603\n",
      "Epoch 20/25\n",
      "5873/5873 [==============================] - 0s 46us/step - loss: 0.6094 - acc: 0.6927\n",
      "Epoch 21/25\n",
      "5873/5873 [==============================] - 0s 77us/step - loss: 0.6027 - acc: 0.6981\n",
      "Epoch 22/25\n",
      "5873/5873 [==============================] - 0s 63us/step - loss: 0.5846 - acc: 0.7076\n",
      "Epoch 23/25\n",
      "5873/5873 [==============================] - 0s 60us/step - loss: 0.5732 - acc: 0.7194\n",
      "Epoch 24/25\n",
      "5873/5873 [==============================] - 0s 78us/step - loss: 0.5420 - acc: 0.7363\n",
      "Epoch 25/25\n",
      "5873/5873 [==============================] - 0s 65us/step - loss: 0.5184 - acc: 0.7466\n",
      "2518/2518 [==============================] - 0s 70us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=91, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=25,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM MODELLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5873/5873 [==============================] - 114s 19ms/step - loss: 0.0405 - acc: 0.9903\n",
      "Epoch 2/2\n",
      "5873/5873 [==============================] - 96s 16ms/step - loss: 2.3289e-07 - acc: 1.0000\n",
      "2518/2518 [==============================] - 8s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "max_features = 3000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=20, epochs=2)\n",
    "score = model.evaluate(x_test, y_test, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
