{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (8391, 91)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.99694</th>\n",
       "      <th>1.2771</th>\n",
       "      <th>1.29</th>\n",
       "      <th>0.16234</th>\n",
       "      <th>0.21899</th>\n",
       "      <th>0.63294</th>\n",
       "      <th>1.8593</th>\n",
       "      <th>2.4524</th>\n",
       "      <th>0.18744</th>\n",
       "      <th>0.59947</th>\n",
       "      <th>0.76399</th>\n",
       "      <th>2.4999</th>\n",
       "      <th>0.20165</th>\n",
       "      <th>0.64587</th>\n",
       "      <th>2.4696</th>\n",
       "      <th>0.30758</th>\n",
       "      <th>0.0086502</th>\n",
       "      <th>0.75937</th>\n",
       "      <th>0.80735</th>\n",
       "      <th>0.44883</th>\n",
       "      <th>0.2202</th>\n",
       "      <th>0.048213</th>\n",
       "      <th>0.56816</th>\n",
       "      <th>2.22</th>\n",
       "      <th>0.13759</th>\n",
       "      <th>0.22783</th>\n",
       "      <th>2.3247</th>\n",
       "      <th>3.8245</th>\n",
       "      <th>0.16294</th>\n",
       "      <th>0.45981</th>\n",
       "      <th>0.63093</th>\n",
       "      <th>2.5048</th>\n",
       "      <th>0.22467</th>\n",
       "      <th>0.6429</th>\n",
       "      <th>2.6522</th>\n",
       "      <th>1.4054</th>\n",
       "      <th>0.0033433</th>\n",
       "      <th>3.0989</th>\n",
       "      <th>1.9315</th>\n",
       "      <th>0.029908</th>\n",
       "      <th>0.94401</th>\n",
       "      <th>0.31607</th>\n",
       "      <th>0.021917</th>\n",
       "      <th>0.28851</th>\n",
       "      <th>1.4024</th>\n",
       "      <th>0.49674</th>\n",
       "      <th>0.27869</th>\n",
       "      <th>0.36769</th>\n",
       "      <th>0.15285</th>\n",
       "      <th>0.1606</th>\n",
       "      <th>0.1328</th>\n",
       "      <th>0.17606</th>\n",
       "      <th>0.3842</th>\n",
       "      <th>0.19877</th>\n",
       "      <th>0.17507</th>\n",
       "      <th>0.10564</th>\n",
       "      <th>0.3156</th>\n",
       "      <th>0.14643</th>\n",
       "      <th>0.10827</th>\n",
       "      <th>1.2166</th>\n",
       "      <th>0.073472</th>\n",
       "      <th>0.037876</th>\n",
       "      <th>0.26714</th>\n",
       "      <th>0.49989</th>\n",
       "      <th>0.094403</th>\n",
       "      <th>0.037798</th>\n",
       "      <th>0.0073178</th>\n",
       "      <th>0.6007</th>\n",
       "      <th>2.7036</th>\n",
       "      <th>0.18483</th>\n",
       "      <th>0.14811</th>\n",
       "      <th>0.17573</th>\n",
       "      <th>1.3432</th>\n",
       "      <th>0.17928</th>\n",
       "      <th>0.10368</th>\n",
       "      <th>0.15127</th>\n",
       "      <th>0.16376</th>\n",
       "      <th>0.13955</th>\n",
       "      <th>0.16332</th>\n",
       "      <th>0.21231</th>\n",
       "      <th>0.85415</th>\n",
       "      <th>0.026382</th>\n",
       "      <th>0.47723</th>\n",
       "      <th>0.49575</th>\n",
       "      <th>0.020878</th>\n",
       "      <th>0.56216</th>\n",
       "      <th>0.072675</th>\n",
       "      <th>0.012301</th>\n",
       "      <th>0.20969</th>\n",
       "      <th>0.96803</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.18280</td>\n",
       "      <td>1.92420</td>\n",
       "      <td>2.89950</td>\n",
       "      <td>1.13280</td>\n",
       "      <td>1.13810</td>\n",
       "      <td>0.83158</td>\n",
       "      <td>1.47320</td>\n",
       "      <td>2.17720</td>\n",
       "      <td>1.29650</td>\n",
       "      <td>0.87671</td>\n",
       "      <td>0.81847</td>\n",
       "      <td>1.99860</td>\n",
       "      <td>1.26430</td>\n",
       "      <td>1.00850</td>\n",
       "      <td>1.06010</td>\n",
       "      <td>0.14574</td>\n",
       "      <td>0.008549</td>\n",
       "      <td>0.29081</td>\n",
       "      <td>1.09880</td>\n",
       "      <td>0.26210</td>\n",
       "      <td>0.067930</td>\n",
       "      <td>0.011935</td>\n",
       "      <td>0.49663</td>\n",
       "      <td>1.23840</td>\n",
       "      <td>1.16450</td>\n",
       "      <td>1.17330</td>\n",
       "      <td>1.85330</td>\n",
       "      <td>5.24300</td>\n",
       "      <td>1.17210</td>\n",
       "      <td>1.02840</td>\n",
       "      <td>0.90230</td>\n",
       "      <td>1.82280</td>\n",
       "      <td>1.02210</td>\n",
       "      <td>0.85610</td>\n",
       "      <td>1.78340</td>\n",
       "      <td>2.27350</td>\n",
       "      <td>0.028813</td>\n",
       "      <td>0.77116</td>\n",
       "      <td>1.8169</td>\n",
       "      <td>0.022705</td>\n",
       "      <td>0.97292</td>\n",
       "      <td>0.11359</td>\n",
       "      <td>0.011999</td>\n",
       "      <td>0.22265</td>\n",
       "      <td>1.56620</td>\n",
       "      <td>0.33987</td>\n",
       "      <td>0.30726</td>\n",
       "      <td>0.41558</td>\n",
       "      <td>0.08913</td>\n",
       "      <td>0.050547</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>0.39323</td>\n",
       "      <td>0.38360</td>\n",
       "      <td>0.10949</td>\n",
       "      <td>0.051013</td>\n",
       "      <td>0.124610</td>\n",
       "      <td>0.51566</td>\n",
       "      <td>0.056842</td>\n",
       "      <td>0.089739</td>\n",
       "      <td>0.95321</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>0.20235</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.10590</td>\n",
       "      <td>0.058022</td>\n",
       "      <td>0.028189</td>\n",
       "      <td>0.43421</td>\n",
       "      <td>1.9649</td>\n",
       "      <td>0.087969</td>\n",
       "      <td>0.044731</td>\n",
       "      <td>0.51849</td>\n",
       "      <td>0.90723</td>\n",
       "      <td>0.10015</td>\n",
       "      <td>0.10919</td>\n",
       "      <td>0.081483</td>\n",
       "      <td>0.48297</td>\n",
       "      <td>0.074608</td>\n",
       "      <td>0.084228</td>\n",
       "      <td>0.50551</td>\n",
       "      <td>1.08410</td>\n",
       "      <td>0.024939</td>\n",
       "      <td>0.44242</td>\n",
       "      <td>1.10520</td>\n",
       "      <td>0.059324</td>\n",
       "      <td>0.59389</td>\n",
       "      <td>0.104870</td>\n",
       "      <td>0.015580</td>\n",
       "      <td>0.28607</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45902</td>\n",
       "      <td>0.63984</td>\n",
       "      <td>0.52790</td>\n",
       "      <td>0.43303</td>\n",
       "      <td>0.32893</td>\n",
       "      <td>0.30588</td>\n",
       "      <td>0.39026</td>\n",
       "      <td>0.64604</td>\n",
       "      <td>0.33423</td>\n",
       "      <td>0.36588</td>\n",
       "      <td>0.45248</td>\n",
       "      <td>0.70728</td>\n",
       "      <td>0.39669</td>\n",
       "      <td>0.34817</td>\n",
       "      <td>1.92130</td>\n",
       "      <td>0.10301</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.92817</td>\n",
       "      <td>1.10570</td>\n",
       "      <td>0.15010</td>\n",
       "      <td>0.090113</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.93769</td>\n",
       "      <td>2.64810</td>\n",
       "      <td>0.30824</td>\n",
       "      <td>0.32064</td>\n",
       "      <td>0.40061</td>\n",
       "      <td>1.83140</td>\n",
       "      <td>0.40939</td>\n",
       "      <td>0.28916</td>\n",
       "      <td>0.28781</td>\n",
       "      <td>0.47195</td>\n",
       "      <td>0.41709</td>\n",
       "      <td>0.34250</td>\n",
       "      <td>0.66613</td>\n",
       "      <td>0.22755</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>1.53380</td>\n",
       "      <td>1.1425</td>\n",
       "      <td>0.071510</td>\n",
       "      <td>1.17730</td>\n",
       "      <td>0.16136</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>0.70938</td>\n",
       "      <td>1.59530</td>\n",
       "      <td>1.05390</td>\n",
       "      <td>0.62420</td>\n",
       "      <td>0.76443</td>\n",
       "      <td>0.16515</td>\n",
       "      <td>0.130160</td>\n",
       "      <td>0.12405</td>\n",
       "      <td>0.20658</td>\n",
       "      <td>0.31734</td>\n",
       "      <td>0.13543</td>\n",
       "      <td>0.107550</td>\n",
       "      <td>0.088628</td>\n",
       "      <td>0.33618</td>\n",
       "      <td>0.099163</td>\n",
       "      <td>0.125450</td>\n",
       "      <td>0.64630</td>\n",
       "      <td>0.090369</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.25628</td>\n",
       "      <td>1.07740</td>\n",
       "      <td>0.13179</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>1.07990</td>\n",
       "      <td>4.8933</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>0.139830</td>\n",
       "      <td>0.23447</td>\n",
       "      <td>1.73950</td>\n",
       "      <td>0.12676</td>\n",
       "      <td>0.10518</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.34223</td>\n",
       "      <td>0.138360</td>\n",
       "      <td>0.132510</td>\n",
       "      <td>0.37558</td>\n",
       "      <td>1.01080</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>0.37524</td>\n",
       "      <td>0.96673</td>\n",
       "      <td>0.016728</td>\n",
       "      <td>0.68470</td>\n",
       "      <td>0.110690</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>0.39180</td>\n",
       "      <td>1.6939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25135</td>\n",
       "      <td>0.18315</td>\n",
       "      <td>0.32631</td>\n",
       "      <td>0.71012</td>\n",
       "      <td>0.81870</td>\n",
       "      <td>0.93663</td>\n",
       "      <td>0.74767</td>\n",
       "      <td>1.03150</td>\n",
       "      <td>0.96265</td>\n",
       "      <td>1.03680</td>\n",
       "      <td>1.04650</td>\n",
       "      <td>0.91701</td>\n",
       "      <td>0.47774</td>\n",
       "      <td>0.92116</td>\n",
       "      <td>1.96730</td>\n",
       "      <td>0.14023</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>0.53291</td>\n",
       "      <td>0.89489</td>\n",
       "      <td>0.36790</td>\n",
       "      <td>0.202050</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.60279</td>\n",
       "      <td>1.31290</td>\n",
       "      <td>0.79119</td>\n",
       "      <td>0.64746</td>\n",
       "      <td>0.58280</td>\n",
       "      <td>0.66389</td>\n",
       "      <td>0.81884</td>\n",
       "      <td>0.85160</td>\n",
       "      <td>0.91678</td>\n",
       "      <td>0.75924</td>\n",
       "      <td>0.65891</td>\n",
       "      <td>1.02550</td>\n",
       "      <td>1.16850</td>\n",
       "      <td>0.40159</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>1.52500</td>\n",
       "      <td>1.9702</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>1.48150</td>\n",
       "      <td>0.19290</td>\n",
       "      <td>0.026342</td>\n",
       "      <td>0.38661</td>\n",
       "      <td>1.17610</td>\n",
       "      <td>0.52938</td>\n",
       "      <td>0.55425</td>\n",
       "      <td>1.15230</td>\n",
       "      <td>0.19599</td>\n",
       "      <td>0.250720</td>\n",
       "      <td>0.19250</td>\n",
       "      <td>0.54821</td>\n",
       "      <td>0.61870</td>\n",
       "      <td>0.12645</td>\n",
       "      <td>0.168630</td>\n",
       "      <td>0.244610</td>\n",
       "      <td>0.60914</td>\n",
       "      <td>0.117480</td>\n",
       "      <td>0.330410</td>\n",
       "      <td>0.47010</td>\n",
       "      <td>0.085636</td>\n",
       "      <td>0.017348</td>\n",
       "      <td>0.20298</td>\n",
       "      <td>0.65430</td>\n",
       "      <td>0.15865</td>\n",
       "      <td>0.098377</td>\n",
       "      <td>0.014396</td>\n",
       "      <td>0.46024</td>\n",
       "      <td>2.1021</td>\n",
       "      <td>0.162640</td>\n",
       "      <td>0.204620</td>\n",
       "      <td>0.60344</td>\n",
       "      <td>1.20830</td>\n",
       "      <td>0.17429</td>\n",
       "      <td>0.26372</td>\n",
       "      <td>0.266520</td>\n",
       "      <td>0.60820</td>\n",
       "      <td>0.142750</td>\n",
       "      <td>0.207760</td>\n",
       "      <td>0.54600</td>\n",
       "      <td>0.67547</td>\n",
       "      <td>0.024906</td>\n",
       "      <td>0.36123</td>\n",
       "      <td>0.80062</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>0.33890</td>\n",
       "      <td>0.129660</td>\n",
       "      <td>0.024569</td>\n",
       "      <td>0.12719</td>\n",
       "      <td>1.2756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.80050</td>\n",
       "      <td>1.06440</td>\n",
       "      <td>1.34030</td>\n",
       "      <td>0.38149</td>\n",
       "      <td>0.34061</td>\n",
       "      <td>0.34281</td>\n",
       "      <td>0.65299</td>\n",
       "      <td>0.94472</td>\n",
       "      <td>0.36371</td>\n",
       "      <td>0.36508</td>\n",
       "      <td>0.35928</td>\n",
       "      <td>1.01510</td>\n",
       "      <td>0.38112</td>\n",
       "      <td>0.42390</td>\n",
       "      <td>0.87211</td>\n",
       "      <td>0.15557</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.41830</td>\n",
       "      <td>1.02800</td>\n",
       "      <td>0.23435</td>\n",
       "      <td>0.135650</td>\n",
       "      <td>0.027006</td>\n",
       "      <td>0.68628</td>\n",
       "      <td>1.39610</td>\n",
       "      <td>0.36923</td>\n",
       "      <td>0.46516</td>\n",
       "      <td>0.87598</td>\n",
       "      <td>3.07020</td>\n",
       "      <td>0.35304</td>\n",
       "      <td>0.34103</td>\n",
       "      <td>0.40550</td>\n",
       "      <td>0.74733</td>\n",
       "      <td>0.34487</td>\n",
       "      <td>0.45965</td>\n",
       "      <td>0.76641</td>\n",
       "      <td>0.67482</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.64233</td>\n",
       "      <td>1.3997</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.96297</td>\n",
       "      <td>0.14542</td>\n",
       "      <td>0.047650</td>\n",
       "      <td>0.51324</td>\n",
       "      <td>1.81600</td>\n",
       "      <td>0.41048</td>\n",
       "      <td>0.57873</td>\n",
       "      <td>1.08700</td>\n",
       "      <td>0.19010</td>\n",
       "      <td>0.197860</td>\n",
       "      <td>0.11049</td>\n",
       "      <td>0.34741</td>\n",
       "      <td>0.58997</td>\n",
       "      <td>0.19465</td>\n",
       "      <td>0.156660</td>\n",
       "      <td>0.148360</td>\n",
       "      <td>0.53857</td>\n",
       "      <td>0.166250</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.30715</td>\n",
       "      <td>0.101420</td>\n",
       "      <td>0.020980</td>\n",
       "      <td>0.10767</td>\n",
       "      <td>0.64258</td>\n",
       "      <td>0.15074</td>\n",
       "      <td>0.077904</td>\n",
       "      <td>0.017428</td>\n",
       "      <td>0.68062</td>\n",
       "      <td>5.7181</td>\n",
       "      <td>0.205440</td>\n",
       "      <td>0.252340</td>\n",
       "      <td>0.45411</td>\n",
       "      <td>1.91860</td>\n",
       "      <td>0.25689</td>\n",
       "      <td>0.16264</td>\n",
       "      <td>0.131340</td>\n",
       "      <td>0.40475</td>\n",
       "      <td>0.157090</td>\n",
       "      <td>0.132930</td>\n",
       "      <td>0.56202</td>\n",
       "      <td>1.06500</td>\n",
       "      <td>0.033802</td>\n",
       "      <td>0.17266</td>\n",
       "      <td>0.58332</td>\n",
       "      <td>0.029163</td>\n",
       "      <td>0.25033</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.17296</td>\n",
       "      <td>1.3850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99437</td>\n",
       "      <td>0.36646</td>\n",
       "      <td>0.49250</td>\n",
       "      <td>0.50493</td>\n",
       "      <td>0.58822</td>\n",
       "      <td>0.67950</td>\n",
       "      <td>1.59060</td>\n",
       "      <td>1.88620</td>\n",
       "      <td>0.31023</td>\n",
       "      <td>0.69369</td>\n",
       "      <td>0.69312</td>\n",
       "      <td>2.07770</td>\n",
       "      <td>0.37823</td>\n",
       "      <td>0.72718</td>\n",
       "      <td>1.23070</td>\n",
       "      <td>0.29847</td>\n",
       "      <td>0.031051</td>\n",
       "      <td>0.66862</td>\n",
       "      <td>1.08450</td>\n",
       "      <td>0.46272</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.018029</td>\n",
       "      <td>0.56068</td>\n",
       "      <td>0.74914</td>\n",
       "      <td>0.43424</td>\n",
       "      <td>0.47597</td>\n",
       "      <td>1.50360</td>\n",
       "      <td>2.73530</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>0.71446</td>\n",
       "      <td>0.57677</td>\n",
       "      <td>1.86690</td>\n",
       "      <td>0.39865</td>\n",
       "      <td>0.73359</td>\n",
       "      <td>2.01420</td>\n",
       "      <td>0.50678</td>\n",
       "      <td>0.021391</td>\n",
       "      <td>1.45460</td>\n",
       "      <td>2.2594</td>\n",
       "      <td>0.033876</td>\n",
       "      <td>1.02010</td>\n",
       "      <td>0.26510</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.52880</td>\n",
       "      <td>0.95201</td>\n",
       "      <td>0.77517</td>\n",
       "      <td>0.80068</td>\n",
       "      <td>0.60916</td>\n",
       "      <td>0.16913</td>\n",
       "      <td>0.160560</td>\n",
       "      <td>0.25734</td>\n",
       "      <td>0.35381</td>\n",
       "      <td>0.47752</td>\n",
       "      <td>0.17826</td>\n",
       "      <td>0.188030</td>\n",
       "      <td>0.301940</td>\n",
       "      <td>0.43858</td>\n",
       "      <td>0.160930</td>\n",
       "      <td>0.228810</td>\n",
       "      <td>0.68164</td>\n",
       "      <td>0.162150</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.34514</td>\n",
       "      <td>1.06460</td>\n",
       "      <td>0.19471</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>0.98972</td>\n",
       "      <td>4.1287</td>\n",
       "      <td>0.111340</td>\n",
       "      <td>0.207690</td>\n",
       "      <td>0.45164</td>\n",
       "      <td>0.62509</td>\n",
       "      <td>0.13476</td>\n",
       "      <td>0.23337</td>\n",
       "      <td>0.222100</td>\n",
       "      <td>0.45000</td>\n",
       "      <td>0.175680</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.48649</td>\n",
       "      <td>1.39360</td>\n",
       "      <td>0.015676</td>\n",
       "      <td>0.62293</td>\n",
       "      <td>0.80999</td>\n",
       "      <td>0.035136</td>\n",
       "      <td>0.67094</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.35137</td>\n",
       "      <td>1.4768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.99694   1.2771     1.29  0.16234  0.21899  0.63294   1.8593   2.4524  \\\n",
       "0  1.18280  1.92420  2.89950  1.13280  1.13810  0.83158  1.47320  2.17720   \n",
       "1  0.45902  0.63984  0.52790  0.43303  0.32893  0.30588  0.39026  0.64604   \n",
       "2  0.25135  0.18315  0.32631  0.71012  0.81870  0.93663  0.74767  1.03150   \n",
       "3  1.80050  1.06440  1.34030  0.38149  0.34061  0.34281  0.65299  0.94472   \n",
       "4  0.99437  0.36646  0.49250  0.50493  0.58822  0.67950  1.59060  1.88620   \n",
       "\n",
       "   0.18744  0.59947  0.76399   2.4999  0.20165  0.64587   2.4696  0.30758  \\\n",
       "0  1.29650  0.87671  0.81847  1.99860  1.26430  1.00850  1.06010  0.14574   \n",
       "1  0.33423  0.36588  0.45248  0.70728  0.39669  0.34817  1.92130  0.10301   \n",
       "2  0.96265  1.03680  1.04650  0.91701  0.47774  0.92116  1.96730  0.14023   \n",
       "3  0.36371  0.36508  0.35928  1.01510  0.38112  0.42390  0.87211  0.15557   \n",
       "4  0.31023  0.69369  0.69312  2.07770  0.37823  0.72718  1.23070  0.29847   \n",
       "\n",
       "   0.0086502  0.75937  0.80735  0.44883    0.2202  0.048213  0.56816     2.22  \\\n",
       "0   0.008549  0.29081  1.09880  0.26210  0.067930  0.011935  0.49663  1.23840   \n",
       "1   0.012467  0.92817  1.10570  0.15010  0.090113  0.022224  0.93769  2.64810   \n",
       "2   0.021927  0.53291  0.89489  0.36790  0.202050  0.024962  0.60279  1.31290   \n",
       "3   0.021016  0.41830  1.02800  0.23435  0.135650  0.027006  0.68628  1.39610   \n",
       "4   0.031051  0.66862  1.08450  0.46272  0.122200  0.018029  0.56068  0.74914   \n",
       "\n",
       "   0.13759  0.22783   2.3247   3.8245  0.16294  0.45981  0.63093   2.5048  \\\n",
       "0  1.16450  1.17330  1.85330  5.24300  1.17210  1.02840  0.90230  1.82280   \n",
       "1  0.30824  0.32064  0.40061  1.83140  0.40939  0.28916  0.28781  0.47195   \n",
       "2  0.79119  0.64746  0.58280  0.66389  0.81884  0.85160  0.91678  0.75924   \n",
       "3  0.36923  0.46516  0.87598  3.07020  0.35304  0.34103  0.40550  0.74733   \n",
       "4  0.43424  0.47597  1.50360  2.73530  0.65000  0.71446  0.57677  1.86690   \n",
       "\n",
       "   0.22467   0.6429   2.6522   1.4054  0.0033433   3.0989  1.9315  0.029908  \\\n",
       "0  1.02210  0.85610  1.78340  2.27350   0.028813  0.77116  1.8169  0.022705   \n",
       "1  0.41709  0.34250  0.66613  0.22755   0.004028  1.53380  1.1425  0.071510   \n",
       "2  0.65891  1.02550  1.16850  0.40159   0.011451  1.52500  1.9702  0.028340   \n",
       "3  0.34487  0.45965  0.76641  0.67482   0.005014  0.64233  1.3997  0.017446   \n",
       "4  0.39865  0.73359  2.01420  0.50678   0.021391  1.45460  2.2594  0.033876   \n",
       "\n",
       "   0.94401  0.31607  0.021917  0.28851   1.4024  0.49674  0.27869  0.36769  \\\n",
       "0  0.97292  0.11359  0.011999  0.22265  1.56620  0.33987  0.30726  0.41558   \n",
       "1  1.17730  0.16136  0.028611  0.70938  1.59530  1.05390  0.62420  0.76443   \n",
       "2  1.48150  0.19290  0.026342  0.38661  1.17610  0.52938  0.55425  1.15230   \n",
       "3  0.96297  0.14542  0.047650  0.51324  1.81600  0.41048  0.57873  1.08700   \n",
       "4  1.02010  0.26510  0.013233  0.52880  0.95201  0.77517  0.80068  0.60916   \n",
       "\n",
       "   0.15285    0.1606   0.1328  0.17606   0.3842  0.19877   0.17507   0.10564  \\\n",
       "0  0.08913  0.050547  0.06491  0.39323  0.38360  0.10949  0.051013  0.124610   \n",
       "1  0.16515  0.130160  0.12405  0.20658  0.31734  0.13543  0.107550  0.088628   \n",
       "2  0.19599  0.250720  0.19250  0.54821  0.61870  0.12645  0.168630  0.244610   \n",
       "3  0.19010  0.197860  0.11049  0.34741  0.58997  0.19465  0.156660  0.148360   \n",
       "4  0.16913  0.160560  0.25734  0.35381  0.47752  0.17826  0.188030  0.301940   \n",
       "\n",
       "    0.3156   0.14643   0.10827   1.2166  0.073472  0.037876  0.26714  0.49989  \\\n",
       "0  0.51566  0.056842  0.089739  0.95321  0.124440  0.009416  0.20235  0.41769   \n",
       "1  0.33618  0.099163  0.125450  0.64630  0.090369  0.015747  0.25628  1.07740   \n",
       "2  0.60914  0.117480  0.330410  0.47010  0.085636  0.017348  0.20298  0.65430   \n",
       "3  0.53857  0.166250  0.118900  0.30715  0.101420  0.020980  0.10767  0.64258   \n",
       "4  0.43858  0.160930  0.228810  0.68164  0.162150  0.012866  0.34514  1.06460   \n",
       "\n",
       "   0.094403  0.037798  0.0073178   0.6007  2.7036   0.18483   0.14811  \\\n",
       "0   0.10590  0.058022   0.028189  0.43421  1.9649  0.087969  0.044731   \n",
       "1   0.13179  0.080900   0.015028  1.07990  4.8933  0.142960  0.139830   \n",
       "2   0.15865  0.098377   0.014396  0.46024  2.1021  0.162640  0.204620   \n",
       "3   0.15074  0.077904   0.017428  0.68062  5.7181  0.205440  0.252340   \n",
       "4   0.19471  0.067578   0.012543  0.98972  4.1287  0.111340  0.207690   \n",
       "\n",
       "   0.17573   1.3432  0.17928  0.10368   0.15127  0.16376   0.13955   0.16332  \\\n",
       "0  0.51849  0.90723  0.10015  0.10919  0.081483  0.48297  0.074608  0.084228   \n",
       "1  0.23447  1.73950  0.12676  0.10518  0.134100  0.34223  0.138360  0.132510   \n",
       "2  0.60344  1.20830  0.17429  0.26372  0.266520  0.60820  0.142750  0.207760   \n",
       "3  0.45411  1.91860  0.25689  0.16264  0.131340  0.40475  0.157090  0.132930   \n",
       "4  0.45164  0.62509  0.13476  0.23337  0.222100  0.45000  0.175680  0.208500   \n",
       "\n",
       "   0.21231  0.85415  0.026382  0.47723  0.49575  0.020878  0.56216  0.072675  \\\n",
       "0  0.50551  1.08410  0.024939  0.44242  1.10520  0.059324  0.59389  0.104870   \n",
       "1  0.37558  1.01080  0.031025  0.37524  0.96673  0.016728  0.68470  0.110690   \n",
       "2  0.54600  0.67547  0.024906  0.36123  0.80062  0.023526  0.33890  0.129660   \n",
       "3  0.56202  1.06500  0.033802  0.17266  0.58332  0.029163  0.25033  0.070588   \n",
       "4  0.48649  1.39360  0.015676  0.62293  0.80999  0.035136  0.67094  0.128600   \n",
       "\n",
       "   0.012301  0.20969  0.96803  1  \n",
       "0  0.015580  0.28607   0.8052  1  \n",
       "1  0.024799  0.39180   1.6939  1  \n",
       "2  0.024569  0.12719   1.2756  1  \n",
       "3  0.019401  0.17296   1.3850  1  \n",
       "4  0.036664  0.35137   1.4768  1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df=pd.read_csv('45 channel 1sec alpha-gmmapower with labels.csv')\n",
    "\n",
    "\n",
    "print('Number of rows and columns:', df.shape)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Labelling COLUMNS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0.99694', '1.2771', '1.29', '0.16234', '0.21899', '0.63294', '1.8593',\n",
      "       '2.4524', '0.18744', '0.59947', '0.76399', '2.4999', '0.20165',\n",
      "       '0.64587', '2.4696', '0.30758', '0.0086502', '0.75937', '0.80735',\n",
      "       '0.44883', '0.2202', '0.048213', '0.56816', '2.22', '0.13759',\n",
      "       '0.22783', '2.3247', '3.8245', '0.16294', '0.45981', '0.63093',\n",
      "       '2.5048', '0.22467', '0.6429', '2.6522', '1.4054', '0.0033433',\n",
      "       '3.0989', '1.9315', '0.029908', '0.94401', '0.31607', '0.021917',\n",
      "       '0.28851', '1.4024', '0.49674', '0.27869', '0.36769', '0.15285',\n",
      "       '0.1606', '0.1328', '0.17606', '0.3842', '0.19877', '0.17507',\n",
      "       '0.10564', '0.3156', '0.14643', '0.10827', '1.2166', '0.073472',\n",
      "       '0.037876', '0.26714', '0.49989', '0.094403', '0.037798', '0.0073178',\n",
      "       '0.6007', '2.7036', '0.18483', '0.14811', '0.17573', '1.3432',\n",
      "       '0.17928', '0.10368', '0.15127', '0.16376', '0.13955', '0.16332',\n",
      "       '0.21231', '0.85415', '0.026382', '0.47723', '0.49575', '0.020878',\n",
      "       '0.56216', '0.072675', '0.012301', '0.20969', '0.96803', '1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {'0.49674':'a', '0.27869':'b', '0.36769':'c', '0.15285':'cd', '0.1606':'d','0.1328':'de','0.17606':'e','0.3842':'f','0.19877':'g',\n",
    "       '0.17507':'l', '0.10564':'m', '0.3156':'n', '0.14643':'o', '0.10827':'p','1.2166':'q', '0.073472':'r',\n",
    "       '0.037876':'s', '0.26714':'t', '0.49989':'u', '0.094403':'v', '0.037798':'w', '0.0073178':'x', '0.6007':'y',\n",
    "       '2.22':'z', '0.13759':'aa', '0.22783':'bb', '2.3247':'cc', '3.8245':'dd', '0.16294':'ee',\n",
    "       '2.7036':'ff', '0.18483':'gg', '0.16376':'hh', '0.13955':'ii', '0.16332':'jj', '0.21231':'kk',\n",
    "       '0.85415':'ll', '0.026382':'mm', '0.47723':'nn', '0.49575':'oo', '0.020878':'pp', '0.56216':'qq',\n",
    "       '0.072675':'rr','0.012301':'j','0.14811':'ss','0.17573':'tt','1.3432':'uu','0.17928':'vv','0.10368':'ww','0.15127':'xx',\n",
    "       '0.20969':'k','0.96803':'h','1':'labels'}\n",
    "df= df.rename(index=str, columns=new_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking any null Values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8391 entries, 0 to 8390\n",
      "Data columns (total 91 columns):\n",
      "0.99694      8391 non-null float64\n",
      "1.2771       8391 non-null float64\n",
      "1.29         8391 non-null float64\n",
      "0.16234      8391 non-null float64\n",
      "0.21899      8391 non-null float64\n",
      "0.63294      8391 non-null float64\n",
      "1.8593       8391 non-null float64\n",
      "2.4524       8391 non-null float64\n",
      "0.18744      8391 non-null float64\n",
      "0.59947      8391 non-null float64\n",
      "0.76399      8391 non-null float64\n",
      "2.4999       8391 non-null float64\n",
      "0.20165      8391 non-null float64\n",
      "0.64587      8391 non-null float64\n",
      "2.4696       8391 non-null float64\n",
      "0.30758      8391 non-null float64\n",
      "0.0086502    8391 non-null float64\n",
      "0.75937      8391 non-null float64\n",
      "0.80735      8391 non-null float64\n",
      "0.44883      8391 non-null float64\n",
      "0.2202       8391 non-null float64\n",
      "0.048213     8391 non-null float64\n",
      "0.56816      8391 non-null float64\n",
      "z            8391 non-null float64\n",
      "aa           8391 non-null float64\n",
      "bb           8391 non-null float64\n",
      "cc           8391 non-null float64\n",
      "dd           8391 non-null float64\n",
      "ee           8391 non-null float64\n",
      "0.45981      8391 non-null float64\n",
      "0.63093      8391 non-null float64\n",
      "2.5048       8391 non-null float64\n",
      "0.22467      8391 non-null float64\n",
      "0.6429       8391 non-null float64\n",
      "2.6522       8391 non-null float64\n",
      "1.4054       8391 non-null float64\n",
      "0.0033433    8391 non-null float64\n",
      "3.0989       8391 non-null float64\n",
      "1.9315       8391 non-null float64\n",
      "0.029908     8391 non-null float64\n",
      "0.94401      8391 non-null float64\n",
      "0.31607      8391 non-null float64\n",
      "0.021917     8391 non-null float64\n",
      "0.28851      8391 non-null float64\n",
      "1.4024       8391 non-null float64\n",
      "a            8391 non-null float64\n",
      "b            8391 non-null float64\n",
      "c            8391 non-null float64\n",
      "cd           8391 non-null float64\n",
      "d            8391 non-null float64\n",
      "de           8391 non-null float64\n",
      "e            8391 non-null float64\n",
      "f            8391 non-null float64\n",
      "g            8391 non-null float64\n",
      "l            8391 non-null float64\n",
      "m            8391 non-null float64\n",
      "n            8391 non-null float64\n",
      "o            8391 non-null float64\n",
      "p            8391 non-null float64\n",
      "q            8391 non-null float64\n",
      "r            8391 non-null float64\n",
      "s            8391 non-null float64\n",
      "t            8391 non-null float64\n",
      "u            8391 non-null float64\n",
      "v            8391 non-null float64\n",
      "w            8391 non-null float64\n",
      "x            8391 non-null float64\n",
      "y            8391 non-null float64\n",
      "ff           8391 non-null float64\n",
      "gg           8391 non-null float64\n",
      "ss           8391 non-null float64\n",
      "tt           8391 non-null float64\n",
      "uu           8391 non-null float64\n",
      "vv           8391 non-null float64\n",
      "ww           8391 non-null float64\n",
      "xx           8391 non-null float64\n",
      "hh           8391 non-null float64\n",
      "ii           8391 non-null float64\n",
      "jj           8391 non-null float64\n",
      "kk           8391 non-null float64\n",
      "ll           8391 non-null float64\n",
      "mm           8391 non-null float64\n",
      "nn           8391 non-null float64\n",
      "oo           8391 non-null float64\n",
      "pp           8391 non-null float64\n",
      "qq           8391 non-null float64\n",
      "rr           8391 non-null float64\n",
      "j            8391 non-null float64\n",
      "k            8391 non-null float64\n",
      "h            8391 non-null float64\n",
      "labels       8391 non-null int64\n",
      "dtypes: float64(90), int64(1)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0.99694       1.2771         1.29      0.16234      0.21899  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.680212     4.266713     4.358381     9.996456     6.295796   \n",
      "std       6.823723     6.222283     5.658669    13.960113     9.518230   \n",
      "min       0.082963     0.122500     0.088702     0.048642     0.052602   \n",
      "25%       1.349850     1.238600     1.513100     2.677600     1.640950   \n",
      "50%       2.557800     2.266000     2.703100     5.647600     3.423300   \n",
      "75%       5.258750     4.585100     5.087350    11.642500     7.155000   \n",
      "max     113.930000    78.915000   148.430000   213.700000   197.330000   \n",
      "\n",
      "           0.63294       1.8593       2.4524      0.18744      0.59947  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      6.869423     6.545154     8.302750     8.473059     5.647723   \n",
      "std      10.746785    10.680664     9.936116    12.677910     8.453658   \n",
      "min       0.071089     0.171790     0.197540     0.045078     0.043657   \n",
      "25%       1.580800     1.979700     2.766850     2.154200     1.428350   \n",
      "50%       3.417800     3.768700     5.282500     4.432000     3.032200   \n",
      "75%       7.505450     7.483600     9.854150     9.400950     6.462700   \n",
      "max     163.560000   580.600000   166.120000   204.940000   152.760000   \n",
      "\n",
      "           0.76399       2.4999      0.20165      0.64587       2.4696  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.277797     8.568798     6.371385     2.917829     6.425101   \n",
      "std       7.896445    13.893190     9.225498     4.627195     9.883636   \n",
      "min       0.075203     0.174300     0.055157     0.003892     0.102060   \n",
      "25%       1.507000     2.256100     1.599400     0.686800     1.591550   \n",
      "50%       2.885900     4.317700     3.364600     1.439900     3.123100   \n",
      "75%       5.896450     8.790450     7.330300     3.352250     6.890800   \n",
      "max     198.170000   292.190000   149.800000   194.880000   186.410000   \n",
      "\n",
      "           0.30758    0.0086502      0.75937      0.80735      0.44883  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      9.182758     1.822529     1.900849     8.901547    12.848909   \n",
      "std      14.108669     2.649852     8.705053    17.468620    23.156923   \n",
      "min       0.024003     0.001719     0.002452     0.176620     0.040149   \n",
      "25%       2.432850     0.514140     0.377370     2.257400     3.546650   \n",
      "50%       4.816400     1.040800     0.812500     4.104800     6.716100   \n",
      "75%      10.241000     2.198800     1.914750     8.254000    13.530500   \n",
      "max     277.040000   130.950000   748.970000   338.500000   525.010000   \n",
      "\n",
      "            0.2202     0.048213      0.56816            z           aa  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.184149     2.072978     5.822868    11.620797     6.120768   \n",
      "std       7.488946     3.692738    12.205158    19.118401     7.964228   \n",
      "min       0.019364     0.002186     0.016792     0.052182     0.059154   \n",
      "25%       1.429800     0.457800     1.577000     3.503800     1.913400   \n",
      "50%       2.879200     1.118800     3.118800     6.639200     3.747200   \n",
      "75%       5.950550     2.274750     6.438850    12.287500     7.172900   \n",
      "max     131.110000   160.900000   794.740000   410.130000   137.710000   \n",
      "\n",
      "                bb           cc           dd           ee      0.45981  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.124055     4.799556     5.943196     6.447796     5.947976   \n",
      "std       8.225643     6.826754     6.243750     9.730075     9.292132   \n",
      "min       0.024389     0.042428     0.121950     0.038725     0.060799   \n",
      "25%       1.183150     1.467250     2.321550     1.592250     1.517450   \n",
      "50%       2.550700     2.753500     4.164100     3.538900     3.195600   \n",
      "75%       5.715400     5.424700     7.427000     7.507250     6.735450   \n",
      "max     142.740000   156.270000   155.880000   161.890000   193.510000   \n",
      "\n",
      "           0.63093       2.5048      0.22467       0.6429       2.6522  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.754505     6.894343     7.038629     6.566679     6.454629   \n",
      "std       8.307750     9.783904    10.162022    19.639854     9.607925   \n",
      "min       0.053798     0.178660     0.053151     0.048530     0.109270   \n",
      "25%       1.593900     2.011000     1.725500     1.536700     1.647000   \n",
      "50%       3.245500     3.902400     3.777400     3.416600     3.218400   \n",
      "75%       6.482400     7.718450     8.351800     7.509450     7.025250   \n",
      "max     159.990000   175.450000   217.440000  1587.700000   190.190000   \n",
      "\n",
      "            1.4054    0.0033433       3.0989       1.9315     0.029908  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      9.003484     3.498434     4.048647     9.097580     4.358885   \n",
      "std      13.521627     4.911708     7.341300    14.622292     6.707393   \n",
      "min       0.110860     0.001304     0.029234     0.077371     0.003185   \n",
      "25%       2.190300     0.833705     0.758680     2.361500     0.912245   \n",
      "50%       4.535900     1.900900     1.672600     4.579900     2.078600   \n",
      "75%       9.982100     4.198200     4.077400     9.790500     5.014750   \n",
      "max     243.920000   152.510000   187.770000   258.300000   139.410000   \n",
      "\n",
      "           0.94401      0.31607     0.021917      0.28851       1.4024  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.588745     9.002957     4.212775     3.345934     9.212848   \n",
      "std      10.711398    15.240102     5.540549     4.675819    19.409590   \n",
      "min       0.034208     0.028003     0.003282     0.006439     0.029835   \n",
      "25%       1.060000     2.557850     1.144750     0.932260     2.031750   \n",
      "50%       2.275800     5.026300     2.513300     1.999600     4.353600   \n",
      "75%       4.926400     9.732050     5.119600     4.117750     8.558500   \n",
      "max     743.230000   386.420000   129.170000   157.310000   322.000000   \n",
      "\n",
      "                 a            b            c           cd            d  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      1.793848     1.408637     1.668601     5.297504     1.338683   \n",
      "std       3.779297     2.993216     4.697215    22.797560     3.771786   \n",
      "min       0.069340     0.071170     0.041441     0.029195     0.029953   \n",
      "25%       0.557810     0.395340     0.539525     0.745215     0.357695   \n",
      "50%       0.944410     0.684720     0.897880     1.550700     0.621820   \n",
      "75%       1.756700     1.468150     1.730500     3.101900     1.195550   \n",
      "max      98.518000   120.590000   284.630000   725.290000   171.880000   \n",
      "\n",
      "                de            e            f            g            l  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.862561     1.644785     5.783262     4.993241     0.865916   \n",
      "std       1.368859     8.802944    48.612101    21.531581     1.933451   \n",
      "min       0.033560     0.040783     0.080078     0.027815     0.025045   \n",
      "25%       0.269950     0.430565     0.824965     0.527490     0.269830   \n",
      "50%       0.483020     0.695430     1.620700     1.003100     0.465490   \n",
      "75%       0.917665     1.183300     3.132800     2.138450     0.780645   \n",
      "max      31.985000   379.310000  2832.800000   798.240000    80.538000   \n",
      "\n",
      "                 m            n            o            p            q  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.905211     4.881819     2.038795     0.572346     1.715630   \n",
      "std       2.466949    18.520333    11.077532     1.565252     8.589664   \n",
      "min       0.037770     0.100210     0.028458     0.006808     0.034137   \n",
      "25%       0.264175     0.579745     0.301995     0.125850     0.301415   \n",
      "50%       0.434850     1.018200     0.505930     0.207910     0.487040   \n",
      "75%       0.735580     2.386350     0.979990     0.360665     0.914375   \n",
      "max      95.067000   529.470000   523.900000    26.010000   552.550000   \n",
      "\n",
      "                 r            s            t            u            v  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      3.029604     0.478581     0.427753     2.817415     3.047414   \n",
      "std      10.111877     1.317523     1.502539    10.554451     5.202499   \n",
      "min       0.023601     0.006775     0.006362     0.095258     0.038797   \n",
      "25%       0.482100     0.097959     0.088217     0.442885     0.700250   \n",
      "50%       0.827000     0.155840     0.145930     0.745220     1.332700   \n",
      "75%       1.915700     0.281605     0.250860     1.600250     3.179900   \n",
      "max     354.660000    30.492000    86.271000   504.180000   203.640000   \n",
      "\n",
      "                 w            x            y           ff           gg  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.879887     0.263976     0.819312     2.651374     2.564770   \n",
      "std       1.509913     0.381169     1.606122     4.212779    13.165823   \n",
      "min       0.016527     0.002884     0.017912     0.020876     0.027542   \n",
      "25%       0.248540     0.083457     0.261860     0.755680     0.641495   \n",
      "50%       0.482100     0.180310     0.463680     1.591200     1.176100   \n",
      "75%       0.909135     0.320550     0.840685     3.138750     2.322050   \n",
      "max      51.866000    20.506000    79.351000   122.820000   664.060000   \n",
      "\n",
      "                ss           tt           uu           vv           ww  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      1.147431     1.222058     2.673551     2.645695     0.921185   \n",
      "std       2.521003     5.200145    10.904946    11.401909     2.042878   \n",
      "min       0.029078     0.074560     0.076679     0.030139     0.033922   \n",
      "25%       0.300460     0.369650     0.705940     0.461200     0.295145   \n",
      "50%       0.586840     0.626510     1.236400     0.903250     0.507320   \n",
      "75%       1.215900     1.140050     2.357200     1.930800     0.897245   \n",
      "max      81.941000   268.160000   423.730000   667.290000    81.514000   \n",
      "\n",
      "                xx           hh           ii           jj           kk  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.890865     2.773500     2.734469     1.151317     2.152318   \n",
      "std       3.201603    12.614676    12.322329     3.465113    25.541864   \n",
      "min       0.038096     0.069410     0.031959     0.026086     0.030351   \n",
      "25%       0.294835     0.510790     0.356535     0.263370     0.357905   \n",
      "50%       0.502300     0.863660     0.617660     0.466350     0.581610   \n",
      "75%       0.854475     1.698400     1.404300     0.830255     1.005200   \n",
      "max     137.910000   480.610000   562.610000    82.064000  1329.100000   \n",
      "\n",
      "                ll           mm           nn           oo           pp  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      3.149071     0.769993     0.898784     4.180781     0.911223   \n",
      "std      11.016938     3.786245     6.595685    16.942836     3.430840   \n",
      "min       0.035556     0.006246     0.014751     0.084381     0.004895   \n",
      "25%       0.573315     0.158715     0.155900     0.529000     0.181375   \n",
      "50%       1.037300     0.253240     0.253410     0.978950     0.309980   \n",
      "75%       2.187300     0.430755     0.432600     2.472700     0.589015   \n",
      "max     546.600000   226.540000   484.500000   914.600000   175.210000   \n",
      "\n",
      "                qq           rr            j            k            h  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.881416     1.521549     0.690855     0.472577     1.461677   \n",
      "std       2.872215     3.007024     1.248386     0.825684     2.437873   \n",
      "min       0.019788     0.021258     0.007599     0.010537     0.019394   \n",
      "25%       0.192360     0.448675     0.206480     0.163325     0.401860   \n",
      "50%       0.335680     0.819900     0.360830     0.274080     0.717710   \n",
      "75%       0.630945     1.572250     0.710445     0.479140     1.519850   \n",
      "max     161.090000   160.850000    50.843000    22.067000    67.633000   \n",
      "\n",
      "            labels  \n",
      "count  8391.000000  \n",
      "mean      0.424383  \n",
      "std       0.494278  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       1.000000  \n",
      "max       1.000000  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***spliting the file in the data and target class***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:,:-1].values.tolist()\n",
    "target = df.iloc[:,-1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x =df[df.columns[:98]]\n",
    "y =df.labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state =  90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Select numerical columns which needs to be normalized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = x_train[x_train.columns[0:20]]\n",
    "test_norm = x_test[x_test.columns[0:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(train_norm)\n",
    "x_train_norm = std_scale.transform(train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting numpy array to dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.99694    1.2771      1.29   0.16234   0.21899   0.63294    1.8593  \\\n",
      "1585 -0.574809 -0.478664 -0.259870 -0.628864 -0.154049 -0.297376 -0.662377   \n",
      "992   1.025842  3.236589  1.417560  1.757329  0.675966  3.868469  0.696159   \n",
      "8204 -0.576262 -0.397916 -0.196709  0.137886 -0.135022  0.242636  0.167129   \n",
      "4674 -0.373001 -0.512045 -0.423963 -0.412675 -0.327287 -0.311574 -0.328459   \n",
      "3593 -0.346911 -0.239245 -0.323992  0.013752 -0.343723 -0.007083  0.614490   \n",
      "\n",
      "        2.4524   0.18744   0.59947   0.76399    2.4999   0.20165   0.64587  \\\n",
      "1585 -0.750731 -0.316596  0.262810 -0.513902 -0.572479 -0.178767 -0.228254   \n",
      "992   3.211227 -0.373047  0.569718 -0.160057 -0.452776  1.258622 -0.032740   \n",
      "8204  0.278209  0.214960  0.295363  0.489236 -0.040465 -0.084042  0.389735   \n",
      "4674 -0.636181 -0.603127 -0.435563 -0.216817 -0.277460 -0.142008 -0.442595   \n",
      "3593 -0.053239 -0.282781 -0.414003  0.280569  0.043290 -0.332850 -0.125269   \n",
      "\n",
      "        2.4696   0.30758  0.0086502   0.75937   0.80735   0.44883  0.2202  \\\n",
      "1585 -0.369962 -0.530684  -0.367454 -0.048612 -0.395704 -0.426842  1.2677   \n",
      "992  -0.380410  0.099898  -0.128734  0.325282  0.371028 -0.163152  5.1223   \n",
      "8204  1.556137  1.782528   0.165806  0.843727  2.277344  0.210822  9.3477   \n",
      "4674  0.386778 -0.460914   0.728454  0.073673 -0.203789 -0.522872  3.8100   \n",
      "3593  0.318598 -0.340496  -0.242504 -0.142303 -0.300703 -0.228802  3.4216   \n",
      "\n",
      "      0.048213  0.56816        z        aa       bb       cc       dd      ee  \\\n",
      "1585   2.66520   4.5598   7.4755   0.90291   2.4814  0.87988   1.0507  3.0642   \n",
      "992    6.91980  13.3770   4.5502  12.63500  22.1720  2.98920  19.0040  2.7304   \n",
      "8204   1.12080  14.8130  22.5770   3.86180   5.0099  6.29550   7.5109  3.9399   \n",
      "4674   0.81793   2.9421   4.8181   3.41890   1.2427  2.84990   5.5722  4.5349   \n",
      "3593   1.26790   1.7081   6.6163   5.60750   4.1069  8.21940   4.0425  5.8979   \n",
      "\n",
      "      0.45981  0.63093    2.5048  0.22467   0.6429   2.6522   1.4054  \\\n",
      "1585   5.5381   3.2306   0.91077   8.2316   3.1882  0.99948   2.3103   \n",
      "992    4.2847   4.1959  17.96500  11.0260  10.7050  1.27120   3.2647   \n",
      "8204   4.9044   9.7053   8.15790   5.3447   9.4798  6.63220  29.2710   \n",
      "4674   2.9519   3.0385   5.89470   1.0269   3.2377  4.19660   1.7666   \n",
      "3593   3.3224   9.7416  11.23400   1.6252   7.4624  9.75610   3.3173   \n",
      "\n",
      "      0.0033433   3.0989   1.9315  0.029908  0.94401  0.31607  0.021917  \\\n",
      "1585    2.94610   1.2151   2.7254   1.98710   2.2612   2.7194    1.4597   \n",
      "992    20.51800  23.4950  11.4360   0.59974   1.2247  21.2440   12.5060   \n",
      "8204    3.66160   9.4356  36.4680  16.30400  40.0890   8.6478    8.3113   \n",
      "4674    2.20100   4.2802   9.4173   7.36950   8.9857   3.7818    4.1858   \n",
      "3593    0.77452   5.0175   6.2512   4.50580   4.4697   9.2038    4.0098   \n",
      "\n",
      "      0.28851    1.4024        a        b        c       cd        d       de  \\\n",
      "1585   4.0352   3.28450  0.41025  0.45690  1.07410  1.82470  0.54644  0.56053   \n",
      "992    4.0373   0.83574  1.00610  2.40690  0.64532  0.70879  0.59256  0.80249   \n",
      "8204   5.7913  24.01500  0.63479  0.30773  0.22493  1.44200  0.33800  0.38520   \n",
      "4674   1.4933   4.50750  0.17945  0.18313  0.95723  1.08450  0.25695  0.26333   \n",
      "3593   2.0353   3.55010  0.52523  0.40950  0.59370  2.53910  0.91918  0.28009   \n",
      "\n",
      "            e        f        g        l        m        n        o        p  \\\n",
      "1585  0.35243  0.41255  1.12960  0.50276  0.54640  0.43604  0.66069  0.16161   \n",
      "992   0.63992  1.05910  0.73273  0.99858  0.68598  0.51796  1.52020  0.61375   \n",
      "8204  0.38859  0.91401  0.67167  0.51121  0.56966  0.42576  0.39390  0.17495   \n",
      "4674  0.60311  4.16400  0.75793  0.23103  0.22037  4.87650  0.61388  0.22543   \n",
      "3593  0.32164  3.13560  5.35620  0.52412  0.23849  0.71051  1.07650  0.11346   \n",
      "\n",
      "            q        r         s         t        u        v        w  \\\n",
      "1585  0.39126  0.66931  0.101460  0.140210  0.54241  0.59963  0.12799   \n",
      "992   0.49116  0.47339  0.194760  0.336830  0.51838  0.52592  0.31865   \n",
      "8204  0.43582  0.47111  0.155890  0.175520  0.51960  1.09530  0.56097   \n",
      "4674  0.40066  0.69155  0.058713  0.320320  8.42860  1.19430  0.19090   \n",
      "3593  0.32263  0.75360  0.212330  0.094873  1.06040  0.52867  0.26463   \n",
      "\n",
      "            x        y       ff       gg       ss       tt       uu       vv  \\\n",
      "1585  0.17831  0.26956  2.01570  1.50300  0.32121  0.30830  0.39388  1.61130   \n",
      "992   0.22453  0.31628  0.17594  1.59760  1.64460  0.60348  1.57200  0.59453   \n",
      "8204  0.13437  0.35010  0.48837  0.51823  0.70455  0.37480  0.65697  0.57242   \n",
      "4674  0.22955  1.12800  1.60570  0.58278  0.16423  0.25028  1.91010  0.97958   \n",
      "3593  0.14290  0.28100  1.31100  1.55460  0.39088  0.33991  1.17850  1.50690   \n",
      "\n",
      "           ww       xx       hh       ii       jj       kk       ll       mm  \\\n",
      "1585  0.58864  0.45311  0.35266  0.56279  0.51140  0.41124  2.32280  0.16744   \n",
      "992   0.62038  0.60163  1.63110  0.92172  0.93268  0.24598  0.32409  0.99155   \n",
      "8204  0.40545  0.33886  0.40774  0.28121  0.47044  0.47445  0.43872  0.20863   \n",
      "4674  0.27622  0.31304  4.43420  0.63135  0.22749  0.49756  1.20700  0.18473   \n",
      "3593  0.43465  0.34562  0.91453  1.22980  0.26456  0.32631  1.44550  0.39852   \n",
      "\n",
      "            nn       oo       pp        qq       rr        j        k  \\\n",
      "1585  0.210570  2.20210  0.32715  0.334100  0.52873  0.13800  0.11853   \n",
      "992   1.744300  0.61493  0.11584  0.064514  0.53111  0.61982  0.22072   \n",
      "8204  0.403430  0.54597  0.23345  0.461040  0.55209  0.53351  0.24417   \n",
      "4674  0.097617  7.34090  0.14872  1.485300  0.15739  0.12390  0.36224   \n",
      "3593  0.320840  0.55789  0.47813  0.373990  0.31720  0.26340  0.37085   \n",
      "\n",
      "             h  labels  \n",
      "1585  0.242840       1  \n",
      "992   0.048297       1  \n",
      "8204  0.498170       1  \n",
      "4674  1.726800       1  \n",
      "3593  0.668810       1  \n"
     ]
    }
   ],
   "source": [
    "training_norm_col = pd.DataFrame(x_train_norm, index=train_norm.index, columns=train_norm.columns) \n",
    "x_train.update(training_norm_col)\n",
    "print (x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize Testing Data by using mean and SD of training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.99694    1.2771      1.29   0.16234   0.21899   0.63294    1.8593  \\\n",
      "1585 -0.574809 -0.478664 -0.259870 -0.628864 -0.154049 -0.297376 -0.662377   \n",
      "992   1.025842  3.236589  1.417560  1.757329  0.675966  3.868469  0.696159   \n",
      "8204 -0.576262 -0.397916 -0.196709  0.137886 -0.135022  0.242636  0.167129   \n",
      "4674 -0.373001 -0.512045 -0.423963 -0.412675 -0.327287 -0.311574 -0.328459   \n",
      "3593 -0.346911 -0.239245 -0.323992  0.013752 -0.343723 -0.007083  0.614490   \n",
      "\n",
      "        2.4524   0.18744   0.59947   0.76399    2.4999   0.20165   0.64587  \\\n",
      "1585 -0.750731 -0.316596  0.262810 -0.513902 -0.572479 -0.178767 -0.228254   \n",
      "992   3.211227 -0.373047  0.569718 -0.160057 -0.452776  1.258622 -0.032740   \n",
      "8204  0.278209  0.214960  0.295363  0.489236 -0.040465 -0.084042  0.389735   \n",
      "4674 -0.636181 -0.603127 -0.435563 -0.216817 -0.277460 -0.142008 -0.442595   \n",
      "3593 -0.053239 -0.282781 -0.414003  0.280569  0.043290 -0.332850 -0.125269   \n",
      "\n",
      "        2.4696   0.30758  0.0086502   0.75937   0.80735   0.44883  0.2202  \\\n",
      "1585 -0.369962 -0.530684  -0.367454 -0.048612 -0.395704 -0.426842  1.2677   \n",
      "992  -0.380410  0.099898  -0.128734  0.325282  0.371028 -0.163152  5.1223   \n",
      "8204  1.556137  1.782528   0.165806  0.843727  2.277344  0.210822  9.3477   \n",
      "4674  0.386778 -0.460914   0.728454  0.073673 -0.203789 -0.522872  3.8100   \n",
      "3593  0.318598 -0.340496  -0.242504 -0.142303 -0.300703 -0.228802  3.4216   \n",
      "\n",
      "      0.048213  0.56816        z        aa       bb       cc       dd      ee  \\\n",
      "1585   2.66520   4.5598   7.4755   0.90291   2.4814  0.87988   1.0507  3.0642   \n",
      "992    6.91980  13.3770   4.5502  12.63500  22.1720  2.98920  19.0040  2.7304   \n",
      "8204   1.12080  14.8130  22.5770   3.86180   5.0099  6.29550   7.5109  3.9399   \n",
      "4674   0.81793   2.9421   4.8181   3.41890   1.2427  2.84990   5.5722  4.5349   \n",
      "3593   1.26790   1.7081   6.6163   5.60750   4.1069  8.21940   4.0425  5.8979   \n",
      "\n",
      "      0.45981  0.63093    2.5048  0.22467   0.6429   2.6522   1.4054  \\\n",
      "1585   5.5381   3.2306   0.91077   8.2316   3.1882  0.99948   2.3103   \n",
      "992    4.2847   4.1959  17.96500  11.0260  10.7050  1.27120   3.2647   \n",
      "8204   4.9044   9.7053   8.15790   5.3447   9.4798  6.63220  29.2710   \n",
      "4674   2.9519   3.0385   5.89470   1.0269   3.2377  4.19660   1.7666   \n",
      "3593   3.3224   9.7416  11.23400   1.6252   7.4624  9.75610   3.3173   \n",
      "\n",
      "      0.0033433   3.0989   1.9315  0.029908  0.94401  0.31607  0.021917  \\\n",
      "1585    2.94610   1.2151   2.7254   1.98710   2.2612   2.7194    1.4597   \n",
      "992    20.51800  23.4950  11.4360   0.59974   1.2247  21.2440   12.5060   \n",
      "8204    3.66160   9.4356  36.4680  16.30400  40.0890   8.6478    8.3113   \n",
      "4674    2.20100   4.2802   9.4173   7.36950   8.9857   3.7818    4.1858   \n",
      "3593    0.77452   5.0175   6.2512   4.50580   4.4697   9.2038    4.0098   \n",
      "\n",
      "      0.28851    1.4024        a        b        c       cd        d       de  \\\n",
      "1585   4.0352   3.28450  0.41025  0.45690  1.07410  1.82470  0.54644  0.56053   \n",
      "992    4.0373   0.83574  1.00610  2.40690  0.64532  0.70879  0.59256  0.80249   \n",
      "8204   5.7913  24.01500  0.63479  0.30773  0.22493  1.44200  0.33800  0.38520   \n",
      "4674   1.4933   4.50750  0.17945  0.18313  0.95723  1.08450  0.25695  0.26333   \n",
      "3593   2.0353   3.55010  0.52523  0.40950  0.59370  2.53910  0.91918  0.28009   \n",
      "\n",
      "            e        f        g        l        m        n        o        p  \\\n",
      "1585  0.35243  0.41255  1.12960  0.50276  0.54640  0.43604  0.66069  0.16161   \n",
      "992   0.63992  1.05910  0.73273  0.99858  0.68598  0.51796  1.52020  0.61375   \n",
      "8204  0.38859  0.91401  0.67167  0.51121  0.56966  0.42576  0.39390  0.17495   \n",
      "4674  0.60311  4.16400  0.75793  0.23103  0.22037  4.87650  0.61388  0.22543   \n",
      "3593  0.32164  3.13560  5.35620  0.52412  0.23849  0.71051  1.07650  0.11346   \n",
      "\n",
      "            q        r         s         t        u        v        w  \\\n",
      "1585  0.39126  0.66931  0.101460  0.140210  0.54241  0.59963  0.12799   \n",
      "992   0.49116  0.47339  0.194760  0.336830  0.51838  0.52592  0.31865   \n",
      "8204  0.43582  0.47111  0.155890  0.175520  0.51960  1.09530  0.56097   \n",
      "4674  0.40066  0.69155  0.058713  0.320320  8.42860  1.19430  0.19090   \n",
      "3593  0.32263  0.75360  0.212330  0.094873  1.06040  0.52867  0.26463   \n",
      "\n",
      "            x        y       ff       gg       ss       tt       uu       vv  \\\n",
      "1585  0.17831  0.26956  2.01570  1.50300  0.32121  0.30830  0.39388  1.61130   \n",
      "992   0.22453  0.31628  0.17594  1.59760  1.64460  0.60348  1.57200  0.59453   \n",
      "8204  0.13437  0.35010  0.48837  0.51823  0.70455  0.37480  0.65697  0.57242   \n",
      "4674  0.22955  1.12800  1.60570  0.58278  0.16423  0.25028  1.91010  0.97958   \n",
      "3593  0.14290  0.28100  1.31100  1.55460  0.39088  0.33991  1.17850  1.50690   \n",
      "\n",
      "           ww       xx       hh       ii       jj       kk       ll       mm  \\\n",
      "1585  0.58864  0.45311  0.35266  0.56279  0.51140  0.41124  2.32280  0.16744   \n",
      "992   0.62038  0.60163  1.63110  0.92172  0.93268  0.24598  0.32409  0.99155   \n",
      "8204  0.40545  0.33886  0.40774  0.28121  0.47044  0.47445  0.43872  0.20863   \n",
      "4674  0.27622  0.31304  4.43420  0.63135  0.22749  0.49756  1.20700  0.18473   \n",
      "3593  0.43465  0.34562  0.91453  1.22980  0.26456  0.32631  1.44550  0.39852   \n",
      "\n",
      "            nn       oo       pp        qq       rr        j        k  \\\n",
      "1585  0.210570  2.20210  0.32715  0.334100  0.52873  0.13800  0.11853   \n",
      "992   1.744300  0.61493  0.11584  0.064514  0.53111  0.61982  0.22072   \n",
      "8204  0.403430  0.54597  0.23345  0.461040  0.55209  0.53351  0.24417   \n",
      "4674  0.097617  7.34090  0.14872  1.485300  0.15739  0.12390  0.36224   \n",
      "3593  0.320840  0.55789  0.47813  0.373990  0.31720  0.26340  0.37085   \n",
      "\n",
      "             h  labels  \n",
      "1585  0.242840       1  \n",
      "992   0.048297       1  \n",
      "8204  0.498170       1  \n",
      "4674  1.726800       1  \n",
      "3593  0.668810       1  \n"
     ]
    }
   ],
   "source": [
    "x_test_norm = std_scale.transform(test_norm)\n",
    "testing_norm_col = pd.DataFrame(x_test_norm, index=test_norm.index, columns=test_norm.columns) \n",
    "x_test.update(testing_norm_col)\n",
    "print (x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support vector machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2853   66]\n",
      " [2025   91]]\n",
      "Accuracy score : \n",
      "58.47070506454817\n"
     ]
    }
   ],
   "source": [
    "def svm_classifier(): \n",
    "    file_x = '45 channel 1sec alpha-gammapower.csv'\n",
    "    file_y = 'Label.csv'\n",
    "    \n",
    "    X = data\n",
    "    y = target\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=42)\n",
    "   \n",
    "    \t\n",
    "\n",
    "     # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)    \n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # SVM Classifier\n",
    "    clf = SVC(kernel = 'rbf', random_state = 50)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    print(cm)\n",
    "    print(\"Accuracy score : \")\n",
    "    print(accuracy_score(y_test, y_predict)*100)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    svm_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5873/5873 [==============================] - 1s 149us/step - loss: 1.0516 - acc: 0.5253\n",
      "Epoch 2/25\n",
      "5873/5873 [==============================] - 0s 40us/step - loss: 0.8370 - acc: 0.5365\n",
      "Epoch 3/25\n",
      "5873/5873 [==============================] - 0s 49us/step - loss: 0.7642 - acc: 0.5573\n",
      "Epoch 4/25\n",
      "5873/5873 [==============================] - 0s 61us/step - loss: 0.7375 - acc: 0.5716\n",
      "Epoch 5/25\n",
      "5873/5873 [==============================] - 0s 47us/step - loss: 0.7189 - acc: 0.5759\n",
      "Epoch 6/25\n",
      "5873/5873 [==============================] - 0s 39us/step - loss: 0.7024 - acc: 0.5862\n",
      "Epoch 7/25\n",
      "5873/5873 [==============================] - 0s 45us/step - loss: 0.7132 - acc: 0.5844\n",
      "Epoch 8/25\n",
      "5873/5873 [==============================] - 0s 31us/step - loss: 0.6868 - acc: 0.6053\n",
      "Epoch 9/25\n",
      "5873/5873 [==============================] - 0s 30us/step - loss: 0.6809 - acc: 0.6235\n",
      "Epoch 10/25\n",
      "5873/5873 [==============================] - 0s 32us/step - loss: 0.6643 - acc: 0.6504\n",
      "Epoch 11/25\n",
      "5873/5873 [==============================] - 0s 44us/step - loss: 0.6417 - acc: 0.6787\n",
      "Epoch 12/25\n",
      "5873/5873 [==============================] - 0s 37us/step - loss: 0.6250 - acc: 0.6896\n",
      "Epoch 13/25\n",
      "5873/5873 [==============================] - 0s 47us/step - loss: 0.6038 - acc: 0.7105\n",
      "Epoch 14/25\n",
      "5873/5873 [==============================] - 0s 37us/step - loss: 0.5685 - acc: 0.7417\n",
      "Epoch 15/25\n",
      "5873/5873 [==============================] - ETA: 0s - loss: 0.5305 - acc: 0.751 - 0s 32us/step - loss: 0.5287 - acc: 0.7533\n",
      "Epoch 16/25\n",
      "5873/5873 [==============================] - 0s 31us/step - loss: 0.5046 - acc: 0.7788\n",
      "Epoch 17/25\n",
      "5873/5873 [==============================] - 0s 29us/step - loss: 0.4821 - acc: 0.7950\n",
      "Epoch 18/25\n",
      "5873/5873 [==============================] - 0s 26us/step - loss: 0.4537 - acc: 0.8050\n",
      "Epoch 19/25\n",
      "5873/5873 [==============================] - 0s 40us/step - loss: 0.4111 - acc: 0.8268\n",
      "Epoch 20/25\n",
      "5873/5873 [==============================] - 0s 49us/step - loss: 0.3743 - acc: 0.8478\n",
      "Epoch 21/25\n",
      "5873/5873 [==============================] - 0s 54us/step - loss: 0.3472 - acc: 0.8592\n",
      "Epoch 22/25\n",
      "5873/5873 [==============================] - 0s 55us/step - loss: 0.3285 - acc: 0.8675\n",
      "Epoch 23/25\n",
      "5873/5873 [==============================] - 0s 44us/step - loss: 0.3242 - acc: 0.8829\n",
      "Epoch 24/25\n",
      "5873/5873 [==============================] - 0s 35us/step - loss: 0.2810 - acc: 0.8922\n",
      "Epoch 25/25\n",
      "5873/5873 [==============================] - 0s 49us/step - loss: 0.2419 - acc: 0.9065\n",
      "2518/2518 [==============================] - 0s 59us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=91, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=25,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM MODELLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5873/5873 [==============================] - 91s 15ms/step - loss: 0.0459 - acc: 0.9852\n",
      "Epoch 2/10\n",
      "5873/5873 [==============================] - 90s 15ms/step - loss: 2.3005e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "5873/5873 [==============================] - 71s 12ms/step - loss: 1.2263e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "5873/5873 [==============================] - 50s 9ms/step - loss: 1.1296e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "5873/5873 [==============================] - 51s 9ms/step - loss: 1.1285e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "5873/5873 [==============================] - 55s 9ms/step - loss: 1.1021e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "5873/5873 [==============================] - 58s 10ms/step - loss: 1.0987e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "5873/5873 [==============================] - 54s 9ms/step - loss: 1.1044e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "5873/5873 [==============================] - 51s 9ms/step - loss: 1.0929e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "5873/5873 [==============================] - 50s 9ms/step - loss: 1.0868e-07 - acc: 1.0000\n",
      "2518/2518 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "max_features = 3000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=20, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
