{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (8391, 91)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.8474</th>\n",
       "      <th>2.5496</th>\n",
       "      <th>3.3057</th>\n",
       "      <th>0.79513</th>\n",
       "      <th>0.65809</th>\n",
       "      <th>1.124</th>\n",
       "      <th>2.5383</th>\n",
       "      <th>3.4095</th>\n",
       "      <th>0.65106</th>\n",
       "      <th>0.74514</th>\n",
       "      <th>...</th>\n",
       "      <th>0.026382</th>\n",
       "      <th>0.47723</th>\n",
       "      <th>0.49575</th>\n",
       "      <th>0.020878</th>\n",
       "      <th>0.56216</th>\n",
       "      <th>0.072675</th>\n",
       "      <th>0.012301</th>\n",
       "      <th>0.20969</th>\n",
       "      <th>0.96803</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4707</td>\n",
       "      <td>3.1008</td>\n",
       "      <td>4.1147</td>\n",
       "      <td>1.09190</td>\n",
       "      <td>0.71181</td>\n",
       "      <td>0.66584</td>\n",
       "      <td>3.5061</td>\n",
       "      <td>3.6547</td>\n",
       "      <td>0.96855</td>\n",
       "      <td>0.39665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024939</td>\n",
       "      <td>0.44242</td>\n",
       "      <td>1.10520</td>\n",
       "      <td>0.059324</td>\n",
       "      <td>0.59389</td>\n",
       "      <td>0.104870</td>\n",
       "      <td>0.015580</td>\n",
       "      <td>0.28607</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.6760</td>\n",
       "      <td>2.5235</td>\n",
       "      <td>3.5537</td>\n",
       "      <td>0.58044</td>\n",
       "      <td>0.72842</td>\n",
       "      <td>0.67869</td>\n",
       "      <td>2.6074</td>\n",
       "      <td>4.0847</td>\n",
       "      <td>0.53950</td>\n",
       "      <td>0.58255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>0.37524</td>\n",
       "      <td>0.96673</td>\n",
       "      <td>0.016728</td>\n",
       "      <td>0.68470</td>\n",
       "      <td>0.110690</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>0.39180</td>\n",
       "      <td>1.6939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1808</td>\n",
       "      <td>3.3740</td>\n",
       "      <td>3.2831</td>\n",
       "      <td>0.53835</td>\n",
       "      <td>0.57345</td>\n",
       "      <td>0.89629</td>\n",
       "      <td>2.0811</td>\n",
       "      <td>2.5790</td>\n",
       "      <td>0.39929</td>\n",
       "      <td>0.72357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024906</td>\n",
       "      <td>0.36123</td>\n",
       "      <td>0.80062</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>0.33890</td>\n",
       "      <td>0.129660</td>\n",
       "      <td>0.024569</td>\n",
       "      <td>0.12719</td>\n",
       "      <td>1.2756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0524</td>\n",
       "      <td>1.7429</td>\n",
       "      <td>2.8583</td>\n",
       "      <td>0.79286</td>\n",
       "      <td>0.76093</td>\n",
       "      <td>1.05520</td>\n",
       "      <td>3.4418</td>\n",
       "      <td>4.5708</td>\n",
       "      <td>0.64689</td>\n",
       "      <td>0.82814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033802</td>\n",
       "      <td>0.17266</td>\n",
       "      <td>0.58332</td>\n",
       "      <td>0.029163</td>\n",
       "      <td>0.25033</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>0.17296</td>\n",
       "      <td>1.3850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.1339</td>\n",
       "      <td>2.8519</td>\n",
       "      <td>2.7088</td>\n",
       "      <td>0.28756</td>\n",
       "      <td>0.55268</td>\n",
       "      <td>0.69743</td>\n",
       "      <td>1.5512</td>\n",
       "      <td>1.6374</td>\n",
       "      <td>0.42841</td>\n",
       "      <td>0.47238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015676</td>\n",
       "      <td>0.62293</td>\n",
       "      <td>0.80999</td>\n",
       "      <td>0.035136</td>\n",
       "      <td>0.67094</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.35137</td>\n",
       "      <td>1.4768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1.8474  2.5496  3.3057  0.79513  0.65809    1.124  2.5383  3.4095  0.65106  \\\n",
       "0  2.4707  3.1008  4.1147  1.09190  0.71181  0.66584  3.5061  3.6547  0.96855   \n",
       "1  1.6760  2.5235  3.5537  0.58044  0.72842  0.67869  2.6074  4.0847  0.53950   \n",
       "2  3.1808  3.3740  3.2831  0.53835  0.57345  0.89629  2.0811  2.5790  0.39929   \n",
       "3  2.0524  1.7429  2.8583  0.79286  0.76093  1.05520  3.4418  4.5708  0.64689   \n",
       "4  3.1339  2.8519  2.7088  0.28756  0.55268  0.69743  1.5512  1.6374  0.42841   \n",
       "\n",
       "   0.74514  ...  0.026382  0.47723  0.49575  0.020878  0.56216  0.072675  \\\n",
       "0  0.39665  ...  0.024939  0.44242  1.10520  0.059324  0.59389  0.104870   \n",
       "1  0.58255  ...  0.031025  0.37524  0.96673  0.016728  0.68470  0.110690   \n",
       "2  0.72357  ...  0.024906  0.36123  0.80062  0.023526  0.33890  0.129660   \n",
       "3  0.82814  ...  0.033802  0.17266  0.58332  0.029163  0.25033  0.070588   \n",
       "4  0.47238  ...  0.015676  0.62293  0.80999  0.035136  0.67094  0.128600   \n",
       "\n",
       "   0.012301  0.20969  0.96803  1  \n",
       "0  0.015580  0.28607   0.8052  1  \n",
       "1  0.024799  0.39180   1.6939  1  \n",
       "2  0.024569  0.12719   1.2756  1  \n",
       "3  0.019401  0.17296   1.3850  1  \n",
       "4  0.036664  0.35137   1.4768  1  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df=pd.read_csv('45 channel 1sec beta-gammapower with labels.csv')\n",
    "\n",
    "\n",
    "print('Number of rows and columns:', df.shape)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Labelling COLUMNS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1.8474', '2.5496', '3.3057', '0.79513', '0.65809', '1.124', '2.5383',\n",
      "       '3.4095', '0.65106', '0.74514', '1.1123', '3.1651', '0.6468', '0.87493',\n",
      "       '3.3942', '0.36758', '0.057015', '0.96547', '2.4596', '0.50809',\n",
      "       '0.27792', '0.026584', '2.5434', '9.0592', '0.74766', '0.8476',\n",
      "       '2.4937', '7.2495', '0.6375', '0.72856', '0.89065', '2.8962', '0.66011',\n",
      "       '0.84083', '2.9789', '2.606', '0.065345', '1.9741', '4.0469',\n",
      "       '0.077726', '1.7905', '0.37865', '0.055707', '0.74315', '4.4329',\n",
      "       '0.49674', '0.27869', '0.36769', '0.15285', '0.1606', '0.1328',\n",
      "       '0.17606', '0.3842', '0.19877', '0.17507', '0.10564', '0.3156',\n",
      "       '0.14643', '0.10827', '1.2166', '0.073472', '0.037876', '0.26714',\n",
      "       '0.49989', '0.094403', '0.037798', '0.0073178', '0.6007', '2.7036',\n",
      "       '0.18483', '0.14811', '0.17573', '1.3432', '0.17928', '0.10368',\n",
      "       '0.15127', '0.16376', '0.13955', '0.16332', '0.21231', '0.85415',\n",
      "       '0.026382', '0.47723', '0.49575', '0.020878', '0.56216', '0.072675',\n",
      "       '0.012301', '0.20969', '0.96803', '1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {'0.49674':'a', '0.27869':'b', '0.36769':'c', '0.15285':'cd', '0.1606':'d','0.1328':'de','0.17606':'e','0.3842':'f','0.19877':'g',\n",
    "       '0.17507':'l', '0.10564':'m', '0.3156':'n', '0.14643':'o', '0.10827':'p','1.2166':'q', '0.073472':'r',\n",
    "       '0.037876':'s', '0.26714':'t', '0.49989':'u', '0.094403':'v', '0.037798':'w', '0.0073178':'x', '0.6007':'y',\n",
    "       '2.22':'z', '0.13759':'aa', '0.22783':'bb', '2.3247':'cc', '3.8245':'dd', '0.16294':'ee',\n",
    "       '2.7036':'ff', '0.18483':'gg', '0.16376':'hh', '0.13955':'ii', '0.16332':'jj', '0.21231':'kk',\n",
    "       '0.85415':'ll', '0.026382':'mm', '0.47723':'nn', '0.49575':'oo', '0.020878':'pp', '0.56216':'qq',\n",
    "       '0.072675':'rr','0.012301':'j','0.14811':'ss','0.17573':'tt','1.3432':'uu','0.17928':'vv','0.10368':'ww','0.15127':'xx',\n",
    "       '0.20969':'k','0.96803':'h','1':'labels'}\n",
    "df= df.rename(index=str, columns=new_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking any null Values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8391 entries, 0 to 8390\n",
      "Data columns (total 91 columns):\n",
      "1.8474      8391 non-null float64\n",
      "2.5496      8391 non-null float64\n",
      "3.3057      8391 non-null float64\n",
      "0.79513     8391 non-null float64\n",
      "0.65809     8391 non-null float64\n",
      "1.124       8391 non-null float64\n",
      "2.5383      8391 non-null float64\n",
      "3.4095      8391 non-null float64\n",
      "0.65106     8391 non-null float64\n",
      "0.74514     8391 non-null float64\n",
      "1.1123      8391 non-null float64\n",
      "3.1651      8391 non-null float64\n",
      "0.6468      8391 non-null float64\n",
      "0.87493     8391 non-null float64\n",
      "3.3942      8391 non-null float64\n",
      "0.36758     8391 non-null float64\n",
      "0.057015    8391 non-null float64\n",
      "0.96547     8391 non-null float64\n",
      "2.4596      8391 non-null float64\n",
      "0.50809     8391 non-null float64\n",
      "0.27792     8391 non-null float64\n",
      "0.026584    8391 non-null float64\n",
      "2.5434      8391 non-null float64\n",
      "9.0592      8391 non-null float64\n",
      "0.74766     8391 non-null float64\n",
      "0.8476      8391 non-null float64\n",
      "2.4937      8391 non-null float64\n",
      "7.2495      8391 non-null float64\n",
      "0.6375      8391 non-null float64\n",
      "0.72856     8391 non-null float64\n",
      "0.89065     8391 non-null float64\n",
      "2.8962      8391 non-null float64\n",
      "0.66011     8391 non-null float64\n",
      "0.84083     8391 non-null float64\n",
      "2.9789      8391 non-null float64\n",
      "2.606       8391 non-null float64\n",
      "0.065345    8391 non-null float64\n",
      "1.9741      8391 non-null float64\n",
      "4.0469      8391 non-null float64\n",
      "0.077726    8391 non-null float64\n",
      "1.7905      8391 non-null float64\n",
      "0.37865     8391 non-null float64\n",
      "0.055707    8391 non-null float64\n",
      "0.74315     8391 non-null float64\n",
      "4.4329      8391 non-null float64\n",
      "a           8391 non-null float64\n",
      "b           8391 non-null float64\n",
      "c           8391 non-null float64\n",
      "cd          8391 non-null float64\n",
      "d           8391 non-null float64\n",
      "de          8391 non-null float64\n",
      "e           8391 non-null float64\n",
      "f           8391 non-null float64\n",
      "g           8391 non-null float64\n",
      "l           8391 non-null float64\n",
      "m           8391 non-null float64\n",
      "n           8391 non-null float64\n",
      "o           8391 non-null float64\n",
      "p           8391 non-null float64\n",
      "q           8391 non-null float64\n",
      "r           8391 non-null float64\n",
      "s           8391 non-null float64\n",
      "t           8391 non-null float64\n",
      "u           8391 non-null float64\n",
      "v           8391 non-null float64\n",
      "w           8391 non-null float64\n",
      "x           8391 non-null float64\n",
      "y           8391 non-null float64\n",
      "ff          8391 non-null float64\n",
      "gg          8391 non-null float64\n",
      "ss          8391 non-null float64\n",
      "tt          8391 non-null float64\n",
      "uu          8391 non-null float64\n",
      "vv          8391 non-null float64\n",
      "ww          8391 non-null float64\n",
      "xx          8391 non-null float64\n",
      "hh          8391 non-null float64\n",
      "ii          8391 non-null float64\n",
      "jj          8391 non-null float64\n",
      "kk          8391 non-null float64\n",
      "ll          8391 non-null float64\n",
      "mm          8391 non-null float64\n",
      "nn          8391 non-null float64\n",
      "oo          8391 non-null float64\n",
      "pp          8391 non-null float64\n",
      "qq          8391 non-null float64\n",
      "rr          8391 non-null float64\n",
      "j           8391 non-null float64\n",
      "k           8391 non-null float64\n",
      "h           8391 non-null float64\n",
      "labels      8391 non-null int64\n",
      "dtypes: float64(90), int64(1)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1.8474       2.5496       3.3057      0.79513      0.65809  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.229256     4.581593     5.113527    11.637879     5.828835   \n",
      "std       5.455699     5.227413     5.554233    27.871367     7.628745   \n",
      "min       0.488380     0.165730     0.435770     0.216740     0.197270   \n",
      "25%       2.487700     1.885600     2.488900     3.288450     2.137500   \n",
      "50%       3.754900     3.088600     3.760900     6.755200     3.615200   \n",
      "75%       5.965750     5.335400     6.005500    11.739000     6.450550   \n",
      "max     114.150000   182.100000   170.890000  1195.000000   246.470000   \n",
      "\n",
      "             1.124       2.5383       3.4095      0.65106      0.74514  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      5.131929     6.722141    12.008532    10.589621     4.569252   \n",
      "std       6.133803    13.013718    48.352535    29.672747     5.511620   \n",
      "min       0.231350     0.483770     0.802540     0.192770     0.165800   \n",
      "25%       1.820500     2.627250     3.945650     2.590850     1.832350   \n",
      "50%       3.207800     4.027500     6.534400     5.005800     2.974300   \n",
      "75%       5.783400     6.648350    11.093000     9.520150     4.850550   \n",
      "max     126.680000   449.410000  2451.300000  1383.000000   126.450000   \n",
      "\n",
      "            1.1123       3.1651       0.6468      0.87493       3.3942  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.503047    10.709194     5.874474     2.346234     5.524527   \n",
      "std       6.015477    27.749195    13.241138     3.836986    11.903354   \n",
      "min       0.296400     0.717880     0.205490     0.019583     0.208650   \n",
      "25%       1.790200     3.029650     1.934000     0.809420     2.040650   \n",
      "50%       2.857600     5.014500     3.246900     1.324100     3.295700   \n",
      "75%       4.723150     8.898800     5.993700     2.450200     5.882200   \n",
      "max     180.400000  1328.900000   569.760000   144.920000   534.410000   \n",
      "\n",
      "           0.36758     0.057015      0.96547       2.4596      0.50809  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      7.748295     1.652208     1.589141     7.225124     9.609517   \n",
      "std      11.101463     3.027635     7.360296    11.512498     9.986518   \n",
      "min       0.149520     0.017924     0.018404     0.535760     0.215020   \n",
      "25%       3.016450     0.619185     0.540220     2.782100     3.666450   \n",
      "50%       4.754200     0.982070     0.873580     4.337200     6.701100   \n",
      "75%       8.264000     1.658300     1.504700     7.629750    12.535000   \n",
      "max     343.230000   132.540000   639.990000   285.610000   347.060000   \n",
      "\n",
      "           0.27792     0.026584       2.5434       9.0592     0.74766  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.00000   \n",
      "mean      3.367419     1.431923     3.745933     8.878795     7.14773   \n",
      "std       3.017629     2.062826     7.577369     8.673383    16.48962   \n",
      "min       0.085031     0.012885     0.071494     0.179040     0.22693   \n",
      "25%       1.750550     0.621535     1.808950     4.440900     3.06740   \n",
      "50%       2.774200     1.097100     2.989900     7.319700     4.94310   \n",
      "75%       4.147550     1.751650     4.766500    11.310500     8.17010   \n",
      "max     133.170000   142.790000   633.730000   404.330000  1043.30000   \n",
      "\n",
      "            0.8476       2.4937       7.2495       0.6375      0.72856  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.975331     5.071719     7.818976     7.515197     5.157684   \n",
      "std       6.645237     6.868668    12.728261    14.878358     6.629362   \n",
      "min       0.157100     0.309260     0.431030     0.128700     0.287050   \n",
      "25%       1.655950     2.148200     3.473950     2.224150     1.839750   \n",
      "50%       2.910400     3.394600     5.432500     4.177900     3.070600   \n",
      "75%       5.602650     5.603550     8.617050     7.851600     5.397850   \n",
      "max     128.000000   187.780000   458.050000   735.030000   111.550000   \n",
      "\n",
      "           0.89065       2.8962      0.66011      0.84083       2.9789  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      4.925688     8.081620     7.474088     5.372810     6.452662   \n",
      "std       6.181697    15.649229    14.994489    12.334634    26.310679   \n",
      "min       0.250740     0.561420     0.216120     0.182050     0.304390   \n",
      "25%       1.904150     2.821150     2.233850     1.826050     2.147100   \n",
      "50%       3.197400     4.579100     3.949300     3.138100     3.606300   \n",
      "75%       5.504400     8.122400     7.721450     5.798850     6.146650   \n",
      "max     126.680000   467.240000   659.610000   952.200000  1360.300000   \n",
      "\n",
      "             2.606     0.065345       1.9741       4.0469     0.077726  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      8.305620     2.968062     3.317029     9.483537     3.355093   \n",
      "std      15.268513     6.229057     8.943329    19.697778     6.951205   \n",
      "min       0.342240     0.021608     0.122970     0.539790     0.034707   \n",
      "25%       2.873450     1.029000     0.913385     3.207200     1.209500   \n",
      "50%       5.079800     1.739400     1.627800     5.360100     2.087000   \n",
      "75%       9.169350     2.999250     3.196850     9.556850     3.689950   \n",
      "max     769.080000   379.490000   601.620000   995.720000   464.880000   \n",
      "\n",
      "            1.7905      0.37865     0.055707      0.74315       4.4329  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      3.430963     5.775767     2.789094     2.451646     5.613311   \n",
      "std       8.147337     5.267075     2.727323     2.647392     5.150284   \n",
      "min       0.072909     0.155330     0.025637     0.041080     0.114590   \n",
      "25%       1.435550     2.792400     1.335550     1.054800     2.556600   \n",
      "50%       2.407200     4.464800     2.223100     1.866600     4.271100   \n",
      "75%       3.919100     7.307450     3.505200     3.150200     7.147300   \n",
      "max     635.060000   140.940000   132.240000   151.400000   168.840000   \n",
      "\n",
      "                 a            b            c           cd            d  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      1.793848     1.408637     1.668601     5.297504     1.338683   \n",
      "std       3.779297     2.993216     4.697215    22.797560     3.771786   \n",
      "min       0.069340     0.071170     0.041441     0.029195     0.029953   \n",
      "25%       0.557810     0.395340     0.539525     0.745215     0.357695   \n",
      "50%       0.944410     0.684720     0.897880     1.550700     0.621820   \n",
      "75%       1.756700     1.468150     1.730500     3.101900     1.195550   \n",
      "max      98.518000   120.590000   284.630000   725.290000   171.880000   \n",
      "\n",
      "                de            e            f            g            l  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.862561     1.644785     5.783262     4.993241     0.865916   \n",
      "std       1.368859     8.802944    48.612101    21.531581     1.933451   \n",
      "min       0.033560     0.040783     0.080078     0.027815     0.025045   \n",
      "25%       0.269950     0.430565     0.824965     0.527490     0.269830   \n",
      "50%       0.483020     0.695430     1.620700     1.003100     0.465490   \n",
      "75%       0.917665     1.183300     3.132800     2.138450     0.780645   \n",
      "max      31.985000   379.310000  2832.800000   798.240000    80.538000   \n",
      "\n",
      "                 m            n            o            p            q  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.905211     4.881819     2.038795     0.572346     1.715630   \n",
      "std       2.466949    18.520333    11.077532     1.565252     8.589664   \n",
      "min       0.037770     0.100210     0.028458     0.006808     0.034137   \n",
      "25%       0.264175     0.579745     0.301995     0.125850     0.301415   \n",
      "50%       0.434850     1.018200     0.505930     0.207910     0.487040   \n",
      "75%       0.735580     2.386350     0.979990     0.360665     0.914375   \n",
      "max      95.067000   529.470000   523.900000    26.010000   552.550000   \n",
      "\n",
      "                 r            s            t            u            v  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      3.029604     0.478581     0.427753     2.817415     3.047414   \n",
      "std      10.111877     1.317523     1.502539    10.554451     5.202499   \n",
      "min       0.023601     0.006775     0.006362     0.095258     0.038797   \n",
      "25%       0.482100     0.097959     0.088217     0.442885     0.700250   \n",
      "50%       0.827000     0.155840     0.145930     0.745220     1.332700   \n",
      "75%       1.915700     0.281605     0.250860     1.600250     3.179900   \n",
      "max     354.660000    30.492000    86.271000   504.180000   203.640000   \n",
      "\n",
      "                 w            x            y           ff           gg  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.879887     0.263976     0.819312     2.651374     2.564770   \n",
      "std       1.509913     0.381169     1.606122     4.212779    13.165823   \n",
      "min       0.016527     0.002884     0.017912     0.020876     0.027542   \n",
      "25%       0.248540     0.083457     0.261860     0.755680     0.641495   \n",
      "50%       0.482100     0.180310     0.463680     1.591200     1.176100   \n",
      "75%       0.909135     0.320550     0.840685     3.138750     2.322050   \n",
      "max      51.866000    20.506000    79.351000   122.820000   664.060000   \n",
      "\n",
      "                ss           tt           uu           vv           ww  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      1.147431     1.222058     2.673551     2.645695     0.921185   \n",
      "std       2.521003     5.200145    10.904946    11.401909     2.042878   \n",
      "min       0.029078     0.074560     0.076679     0.030139     0.033922   \n",
      "25%       0.300460     0.369650     0.705940     0.461200     0.295145   \n",
      "50%       0.586840     0.626510     1.236400     0.903250     0.507320   \n",
      "75%       1.215900     1.140050     2.357200     1.930800     0.897245   \n",
      "max      81.941000   268.160000   423.730000   667.290000    81.514000   \n",
      "\n",
      "                xx           hh           ii           jj           kk  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.890865     2.773500     2.734469     1.151317     2.152318   \n",
      "std       3.201603    12.614676    12.322329     3.465113    25.541864   \n",
      "min       0.038096     0.069410     0.031959     0.026086     0.030351   \n",
      "25%       0.294835     0.510790     0.356535     0.263370     0.357905   \n",
      "50%       0.502300     0.863660     0.617660     0.466350     0.581610   \n",
      "75%       0.854475     1.698400     1.404300     0.830255     1.005200   \n",
      "max     137.910000   480.610000   562.610000    82.064000  1329.100000   \n",
      "\n",
      "                ll           mm           nn           oo           pp  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      3.149071     0.769993     0.898784     4.180781     0.911223   \n",
      "std      11.016938     3.786245     6.595685    16.942836     3.430840   \n",
      "min       0.035556     0.006246     0.014751     0.084381     0.004895   \n",
      "25%       0.573315     0.158715     0.155900     0.529000     0.181375   \n",
      "50%       1.037300     0.253240     0.253410     0.978950     0.309980   \n",
      "75%       2.187300     0.430755     0.432600     2.472700     0.589015   \n",
      "max     546.600000   226.540000   484.500000   914.600000   175.210000   \n",
      "\n",
      "                qq           rr            j            k            h  \\\n",
      "count  8391.000000  8391.000000  8391.000000  8391.000000  8391.000000   \n",
      "mean      0.881416     1.521549     0.690855     0.472577     1.461677   \n",
      "std       2.872215     3.007024     1.248386     0.825684     2.437873   \n",
      "min       0.019788     0.021258     0.007599     0.010537     0.019394   \n",
      "25%       0.192360     0.448675     0.206480     0.163325     0.401860   \n",
      "50%       0.335680     0.819900     0.360830     0.274080     0.717710   \n",
      "75%       0.630945     1.572250     0.710445     0.479140     1.519850   \n",
      "max     161.090000   160.850000    50.843000    22.067000    67.633000   \n",
      "\n",
      "            labels  \n",
      "count  8391.000000  \n",
      "mean      0.424383  \n",
      "std       0.494278  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       1.000000  \n",
      "max       1.000000  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***spliting the file in the data and target class***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:,:-1].values.tolist()\n",
    "target = df.iloc[:,-1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x =df[df.columns[:98]]\n",
    "y =df.labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state =  90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Select numerical columns which needs to be normalized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = x_train[x_train.columns[0:20]]\n",
    "test_norm = x_test[x_test.columns[0:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(train_norm)\n",
    "x_train_norm = std_scale.transform(train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting numpy array to dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1.8474    2.5496    3.3057   0.79513   0.65809     1.124    2.5383  \\\n",
      "1585 -0.704393 -0.648984 -0.544477 -0.172409 -0.499763 -0.452277 -0.409348   \n",
      "992   1.089735  1.266852  0.315230 -0.175264  0.095827  0.186543  0.035079   \n",
      "8204 -0.312728 -0.551935 -0.668391 -0.082287 -0.274430 -0.142551 -0.107121   \n",
      "4674 -0.740344 -0.697548 -0.286404 -0.323399 -0.461296 -0.299094  0.019298   \n",
      "3593 -0.526019 -0.516390 -0.644418 -0.069662 -0.155176 -0.110209 -0.208143   \n",
      "\n",
      "        3.4095   0.65106   0.74514    1.1123    3.1651    0.6468   0.87493  \\\n",
      "1585 -0.224406 -0.222291 -0.437827 -0.369838 -0.313564 -0.168802 -0.358422   \n",
      "992  -0.117611 -0.111334  0.871970  0.304838 -0.160949  0.164129  0.788301   \n",
      "8204 -0.146851 -0.164145 -0.054605 -0.170290 -0.180806 -0.141512 -0.192981   \n",
      "4674 -0.078842 -0.272849 -0.409093 -0.283618  0.138537 -0.313176 -0.358398   \n",
      "3593 -0.053528 -0.049057  0.061193 -0.193191 -0.220228  0.151731 -0.305296   \n",
      "\n",
      "        3.3942   0.36758  0.057015   0.96547    2.4596   0.50809  0.27792  \\\n",
      "1585 -0.284913 -0.381632 -0.365980 -0.120192 -0.385542 -0.579787  0.44351   \n",
      "992   0.059446 -0.070338  0.221381  0.099262 -0.144087 -0.348497  3.19470   \n",
      "8204  0.040653 -0.424973 -0.290103 -0.098989 -0.395676 -0.686202  1.49820   \n",
      "4674 -0.212823 -0.489947 -0.243474 -0.126650  0.300298 -0.507875  1.38760   \n",
      "3593 -0.173295 -0.117990 -0.221225 -0.134875 -0.337412  0.018544  1.93920   \n",
      "\n",
      "      0.026584  2.5434  9.0592  0.74766   0.8476  2.4937  7.2495  0.6375  \\\n",
      "1585   1.08450  2.6379  5.1807   2.0880   1.8348  1.6220  1.8534  7.4828   \n",
      "992    2.43770  4.1316  1.7157   8.8349  11.1060  6.0024  8.4009  6.3916   \n",
      "8204   0.42358  1.6594  5.3257   4.7446   4.9794  4.9472  3.3693  4.1825   \n",
      "4674   1.50890  1.6841  3.5594   1.3949   1.2639  5.8352  8.7573  2.3154   \n",
      "3593   1.20800  1.9177  5.0406   5.2958   3.5179  2.4645  4.7319  6.0500   \n",
      "\n",
      "      0.72856  0.89065   2.8962  0.66011  0.84083  2.9789   2.606  0.065345  \\\n",
      "1585   2.6757   2.3059   1.8871   2.7727   2.9249  1.6384  8.1130   1.35920   \n",
      "992    6.7306   7.0949   8.1775  10.3730  10.6630  2.8465  2.4838   6.45490   \n",
      "8204   3.6948   4.6589   5.2471   4.2341   3.6483  6.0214  4.5472   1.89050   \n",
      "4674   2.6560   4.3202  11.7580   1.8353   2.1723  4.6194  2.7669   0.89815   \n",
      "3593   4.4628   4.6774   3.5322   6.7474   3.5360  2.9662  9.3998   3.23060   \n",
      "\n",
      "        1.9741   4.0469  0.077726   1.7905  0.37865  0.055707  0.74315  \\\n",
      "1585   0.76051   5.7085   2.41040  1.45570   1.8148   0.63196   1.5633   \n",
      "992   10.24300   6.7296   0.42437  0.69708   6.4759   6.97100   1.6826   \n",
      "8204   3.44380   3.3420   2.18860  2.20380   1.4239   1.57270   0.7503   \n",
      "4674   0.94710  16.0500   1.21940  1.62540   1.5423   1.52060   1.0707   \n",
      "3593   1.41850   3.3889   4.13550  1.13950   6.0627   2.33170   2.2049   \n",
      "\n",
      "       4.4329        a        b        c       cd        d       de        e  \\\n",
      "1585  3.12430  0.41025  0.45690  1.07410  1.82470  0.54644  0.56053  0.35243   \n",
      "992   0.52417  1.00610  2.40690  0.64532  0.70879  0.59256  0.80249  0.63992   \n",
      "8204  2.82600  0.63479  0.30773  0.22493  1.44200  0.33800  0.38520  0.38859   \n",
      "4674  4.18850  0.17945  0.18313  0.95723  1.08450  0.25695  0.26333  0.60311   \n",
      "3593  3.15250  0.52523  0.40950  0.59370  2.53910  0.91918  0.28009  0.32164   \n",
      "\n",
      "            f        g        l        m        n        o        p        q  \\\n",
      "1585  0.41255  1.12960  0.50276  0.54640  0.43604  0.66069  0.16161  0.39126   \n",
      "992   1.05910  0.73273  0.99858  0.68598  0.51796  1.52020  0.61375  0.49116   \n",
      "8204  0.91401  0.67167  0.51121  0.56966  0.42576  0.39390  0.17495  0.43582   \n",
      "4674  4.16400  0.75793  0.23103  0.22037  4.87650  0.61388  0.22543  0.40066   \n",
      "3593  3.13560  5.35620  0.52412  0.23849  0.71051  1.07650  0.11346  0.32263   \n",
      "\n",
      "            r         s         t        u        v        w        x  \\\n",
      "1585  0.66931  0.101460  0.140210  0.54241  0.59963  0.12799  0.17831   \n",
      "992   0.47339  0.194760  0.336830  0.51838  0.52592  0.31865  0.22453   \n",
      "8204  0.47111  0.155890  0.175520  0.51960  1.09530  0.56097  0.13437   \n",
      "4674  0.69155  0.058713  0.320320  8.42860  1.19430  0.19090  0.22955   \n",
      "3593  0.75360  0.212330  0.094873  1.06040  0.52867  0.26463  0.14290   \n",
      "\n",
      "            y       ff       gg       ss       tt       uu       vv       ww  \\\n",
      "1585  0.26956  2.01570  1.50300  0.32121  0.30830  0.39388  1.61130  0.58864   \n",
      "992   0.31628  0.17594  1.59760  1.64460  0.60348  1.57200  0.59453  0.62038   \n",
      "8204  0.35010  0.48837  0.51823  0.70455  0.37480  0.65697  0.57242  0.40545   \n",
      "4674  1.12800  1.60570  0.58278  0.16423  0.25028  1.91010  0.97958  0.27622   \n",
      "3593  0.28100  1.31100  1.55460  0.39088  0.33991  1.17850  1.50690  0.43465   \n",
      "\n",
      "           xx       hh       ii       jj       kk       ll       mm        nn  \\\n",
      "1585  0.45311  0.35266  0.56279  0.51140  0.41124  2.32280  0.16744  0.210570   \n",
      "992   0.60163  1.63110  0.92172  0.93268  0.24598  0.32409  0.99155  1.744300   \n",
      "8204  0.33886  0.40774  0.28121  0.47044  0.47445  0.43872  0.20863  0.403430   \n",
      "4674  0.31304  4.43420  0.63135  0.22749  0.49756  1.20700  0.18473  0.097617   \n",
      "3593  0.34562  0.91453  1.22980  0.26456  0.32631  1.44550  0.39852  0.320840   \n",
      "\n",
      "           oo       pp        qq       rr        j        k         h  labels  \n",
      "1585  2.20210  0.32715  0.334100  0.52873  0.13800  0.11853  0.242840       1  \n",
      "992   0.61493  0.11584  0.064514  0.53111  0.61982  0.22072  0.048297       1  \n",
      "8204  0.54597  0.23345  0.461040  0.55209  0.53351  0.24417  0.498170       1  \n",
      "4674  7.34090  0.14872  1.485300  0.15739  0.12390  0.36224  1.726800       1  \n",
      "3593  0.55789  0.47813  0.373990  0.31720  0.26340  0.37085  0.668810       1  \n"
     ]
    }
   ],
   "source": [
    "training_norm_col = pd.DataFrame(x_train_norm, index=train_norm.index, columns=train_norm.columns) \n",
    "x_train.update(training_norm_col)\n",
    "print (x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize Testing Data by using mean and SD of training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1.8474    2.5496    3.3057   0.79513   0.65809     1.124    2.5383  \\\n",
      "1585 -0.704393 -0.648984 -0.544477 -0.172409 -0.499763 -0.452277 -0.409348   \n",
      "992   1.089735  1.266852  0.315230 -0.175264  0.095827  0.186543  0.035079   \n",
      "8204 -0.312728 -0.551935 -0.668391 -0.082287 -0.274430 -0.142551 -0.107121   \n",
      "4674 -0.740344 -0.697548 -0.286404 -0.323399 -0.461296 -0.299094  0.019298   \n",
      "3593 -0.526019 -0.516390 -0.644418 -0.069662 -0.155176 -0.110209 -0.208143   \n",
      "\n",
      "        3.4095   0.65106   0.74514    1.1123    3.1651    0.6468   0.87493  \\\n",
      "1585 -0.224406 -0.222291 -0.437827 -0.369838 -0.313564 -0.168802 -0.358422   \n",
      "992  -0.117611 -0.111334  0.871970  0.304838 -0.160949  0.164129  0.788301   \n",
      "8204 -0.146851 -0.164145 -0.054605 -0.170290 -0.180806 -0.141512 -0.192981   \n",
      "4674 -0.078842 -0.272849 -0.409093 -0.283618  0.138537 -0.313176 -0.358398   \n",
      "3593 -0.053528 -0.049057  0.061193 -0.193191 -0.220228  0.151731 -0.305296   \n",
      "\n",
      "        3.3942   0.36758  0.057015   0.96547    2.4596   0.50809  0.27792  \\\n",
      "1585 -0.284913 -0.381632 -0.365980 -0.120192 -0.385542 -0.579787  0.44351   \n",
      "992   0.059446 -0.070338  0.221381  0.099262 -0.144087 -0.348497  3.19470   \n",
      "8204  0.040653 -0.424973 -0.290103 -0.098989 -0.395676 -0.686202  1.49820   \n",
      "4674 -0.212823 -0.489947 -0.243474 -0.126650  0.300298 -0.507875  1.38760   \n",
      "3593 -0.173295 -0.117990 -0.221225 -0.134875 -0.337412  0.018544  1.93920   \n",
      "\n",
      "      0.026584  2.5434  9.0592  0.74766   0.8476  2.4937  7.2495  0.6375  \\\n",
      "1585   1.08450  2.6379  5.1807   2.0880   1.8348  1.6220  1.8534  7.4828   \n",
      "992    2.43770  4.1316  1.7157   8.8349  11.1060  6.0024  8.4009  6.3916   \n",
      "8204   0.42358  1.6594  5.3257   4.7446   4.9794  4.9472  3.3693  4.1825   \n",
      "4674   1.50890  1.6841  3.5594   1.3949   1.2639  5.8352  8.7573  2.3154   \n",
      "3593   1.20800  1.9177  5.0406   5.2958   3.5179  2.4645  4.7319  6.0500   \n",
      "\n",
      "      0.72856  0.89065   2.8962  0.66011  0.84083  2.9789   2.606  0.065345  \\\n",
      "1585   2.6757   2.3059   1.8871   2.7727   2.9249  1.6384  8.1130   1.35920   \n",
      "992    6.7306   7.0949   8.1775  10.3730  10.6630  2.8465  2.4838   6.45490   \n",
      "8204   3.6948   4.6589   5.2471   4.2341   3.6483  6.0214  4.5472   1.89050   \n",
      "4674   2.6560   4.3202  11.7580   1.8353   2.1723  4.6194  2.7669   0.89815   \n",
      "3593   4.4628   4.6774   3.5322   6.7474   3.5360  2.9662  9.3998   3.23060   \n",
      "\n",
      "        1.9741   4.0469  0.077726   1.7905  0.37865  0.055707  0.74315  \\\n",
      "1585   0.76051   5.7085   2.41040  1.45570   1.8148   0.63196   1.5633   \n",
      "992   10.24300   6.7296   0.42437  0.69708   6.4759   6.97100   1.6826   \n",
      "8204   3.44380   3.3420   2.18860  2.20380   1.4239   1.57270   0.7503   \n",
      "4674   0.94710  16.0500   1.21940  1.62540   1.5423   1.52060   1.0707   \n",
      "3593   1.41850   3.3889   4.13550  1.13950   6.0627   2.33170   2.2049   \n",
      "\n",
      "       4.4329        a        b        c       cd        d       de        e  \\\n",
      "1585  3.12430  0.41025  0.45690  1.07410  1.82470  0.54644  0.56053  0.35243   \n",
      "992   0.52417  1.00610  2.40690  0.64532  0.70879  0.59256  0.80249  0.63992   \n",
      "8204  2.82600  0.63479  0.30773  0.22493  1.44200  0.33800  0.38520  0.38859   \n",
      "4674  4.18850  0.17945  0.18313  0.95723  1.08450  0.25695  0.26333  0.60311   \n",
      "3593  3.15250  0.52523  0.40950  0.59370  2.53910  0.91918  0.28009  0.32164   \n",
      "\n",
      "            f        g        l        m        n        o        p        q  \\\n",
      "1585  0.41255  1.12960  0.50276  0.54640  0.43604  0.66069  0.16161  0.39126   \n",
      "992   1.05910  0.73273  0.99858  0.68598  0.51796  1.52020  0.61375  0.49116   \n",
      "8204  0.91401  0.67167  0.51121  0.56966  0.42576  0.39390  0.17495  0.43582   \n",
      "4674  4.16400  0.75793  0.23103  0.22037  4.87650  0.61388  0.22543  0.40066   \n",
      "3593  3.13560  5.35620  0.52412  0.23849  0.71051  1.07650  0.11346  0.32263   \n",
      "\n",
      "            r         s         t        u        v        w        x  \\\n",
      "1585  0.66931  0.101460  0.140210  0.54241  0.59963  0.12799  0.17831   \n",
      "992   0.47339  0.194760  0.336830  0.51838  0.52592  0.31865  0.22453   \n",
      "8204  0.47111  0.155890  0.175520  0.51960  1.09530  0.56097  0.13437   \n",
      "4674  0.69155  0.058713  0.320320  8.42860  1.19430  0.19090  0.22955   \n",
      "3593  0.75360  0.212330  0.094873  1.06040  0.52867  0.26463  0.14290   \n",
      "\n",
      "            y       ff       gg       ss       tt       uu       vv       ww  \\\n",
      "1585  0.26956  2.01570  1.50300  0.32121  0.30830  0.39388  1.61130  0.58864   \n",
      "992   0.31628  0.17594  1.59760  1.64460  0.60348  1.57200  0.59453  0.62038   \n",
      "8204  0.35010  0.48837  0.51823  0.70455  0.37480  0.65697  0.57242  0.40545   \n",
      "4674  1.12800  1.60570  0.58278  0.16423  0.25028  1.91010  0.97958  0.27622   \n",
      "3593  0.28100  1.31100  1.55460  0.39088  0.33991  1.17850  1.50690  0.43465   \n",
      "\n",
      "           xx       hh       ii       jj       kk       ll       mm        nn  \\\n",
      "1585  0.45311  0.35266  0.56279  0.51140  0.41124  2.32280  0.16744  0.210570   \n",
      "992   0.60163  1.63110  0.92172  0.93268  0.24598  0.32409  0.99155  1.744300   \n",
      "8204  0.33886  0.40774  0.28121  0.47044  0.47445  0.43872  0.20863  0.403430   \n",
      "4674  0.31304  4.43420  0.63135  0.22749  0.49756  1.20700  0.18473  0.097617   \n",
      "3593  0.34562  0.91453  1.22980  0.26456  0.32631  1.44550  0.39852  0.320840   \n",
      "\n",
      "           oo       pp        qq       rr        j        k         h  labels  \n",
      "1585  2.20210  0.32715  0.334100  0.52873  0.13800  0.11853  0.242840       1  \n",
      "992   0.61493  0.11584  0.064514  0.53111  0.61982  0.22072  0.048297       1  \n",
      "8204  0.54597  0.23345  0.461040  0.55209  0.53351  0.24417  0.498170       1  \n",
      "4674  7.34090  0.14872  1.485300  0.15739  0.12390  0.36224  1.726800       1  \n",
      "3593  0.55789  0.47813  0.373990  0.31720  0.26340  0.37085  0.668810       1  \n"
     ]
    }
   ],
   "source": [
    "x_test_norm = std_scale.transform(test_norm)\n",
    "testing_norm_col = pd.DataFrame(x_test_norm, index=test_norm.index, columns=test_norm.columns) \n",
    "x_test.update(testing_norm_col)\n",
    "print (x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support vector machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2828   91]\n",
      " [2024   92]]\n",
      "Accuracy score : \n",
      "57.994041708043696\n"
     ]
    }
   ],
   "source": [
    "def svm_classifier(): \n",
    "    file_x = '45 channel 1sec beta-gammapower.csv'\n",
    "    file_y = 'Label.csv'\n",
    "    \n",
    "    X = data\n",
    "    y = target\n",
    "    # Split the data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=42)\n",
    "   \n",
    "    \t\n",
    "\n",
    "     # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)    \n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # SVM Classifier\n",
    "    clf = SVC(kernel = 'rbf', random_state = 50)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    print(cm)\n",
    "    print(\"Accuracy score : \")\n",
    "    print(accuracy_score(y_test, y_predict)*100)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    svm_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5873/5873 [==============================] - 1s 107us/step - loss: 1.0821 - acc: 0.5304\n",
      "Epoch 2/25\n",
      "5873/5873 [==============================] - 0s 53us/step - loss: 0.8288 - acc: 0.5738\n",
      "Epoch 3/25\n",
      "5873/5873 [==============================] - 0s 53us/step - loss: 0.7667 - acc: 0.5760\n",
      "Epoch 4/25\n",
      "5873/5873 [==============================] - 0s 32us/step - loss: 0.7259 - acc: 0.5900\n",
      "Epoch 5/25\n",
      "5873/5873 [==============================] - 0s 45us/step - loss: 0.7140 - acc: 0.6067\n",
      "Epoch 6/25\n",
      "5873/5873 [==============================] - 0s 58us/step - loss: 0.6939 - acc: 0.6264\n",
      "Epoch 7/25\n",
      "5873/5873 [==============================] - 0s 57us/step - loss: 0.6833 - acc: 0.6477\n",
      "Epoch 8/25\n",
      "5873/5873 [==============================] - 0s 25us/step - loss: 0.6723 - acc: 0.6639\n",
      "Epoch 9/25\n",
      "5873/5873 [==============================] - 0s 34us/step - loss: 0.6457 - acc: 0.6816\n",
      "Epoch 10/25\n",
      "5873/5873 [==============================] - 0s 39us/step - loss: 0.6185 - acc: 0.7061\n",
      "Epoch 11/25\n",
      "5873/5873 [==============================] - 0s 43us/step - loss: 0.5754 - acc: 0.7369\n",
      "Epoch 12/25\n",
      "5873/5873 [==============================] - 0s 39us/step - loss: 0.5386 - acc: 0.7609\n",
      "Epoch 13/25\n",
      "5873/5873 [==============================] - 0s 30us/step - loss: 0.5093 - acc: 0.7804\n",
      "Epoch 14/25\n",
      "5873/5873 [==============================] - 0s 43us/step - loss: 0.4674 - acc: 0.8096\n",
      "Epoch 15/25\n",
      "5873/5873 [==============================] - 0s 40us/step - loss: 0.4477 - acc: 0.8272\n",
      "Epoch 16/25\n",
      "5873/5873 [==============================] - 0s 33us/step - loss: 0.4057 - acc: 0.8388\n",
      "Epoch 17/25\n",
      "5873/5873 [==============================] - 0s 32us/step - loss: 0.3612 - acc: 0.8602\n",
      "Epoch 18/25\n",
      "5873/5873 [==============================] - 0s 31us/step - loss: 0.3412 - acc: 0.8686\n",
      "Epoch 19/25\n",
      "5873/5873 [==============================] - 0s 31us/step - loss: 0.3045 - acc: 0.8847\n",
      "Epoch 20/25\n",
      "5873/5873 [==============================] - 0s 34us/step - loss: 0.2893 - acc: 0.8977\n",
      "Epoch 21/25\n",
      "5873/5873 [==============================] - 0s 26us/step - loss: 0.2529 - acc: 0.9116\n",
      "Epoch 22/25\n",
      "5873/5873 [==============================] - 0s 34us/step - loss: 0.2356 - acc: 0.9162\n",
      "Epoch 23/25\n",
      "5873/5873 [==============================] - 0s 35us/step - loss: 0.2202 - acc: 0.9178\n",
      "Epoch 24/25\n",
      "5873/5873 [==============================] - 0s 44us/step - loss: 0.1920 - acc: 0.9244\n",
      "Epoch 25/25\n",
      "5873/5873 [==============================] - 0s 38us/step - loss: 0.1771 - acc: 0.9380\n",
      "2518/2518 [==============================] - 0s 48us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=91, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=25,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM MODELLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5873/5873 [==============================] - 56s 10ms/step - loss: 0.0477 - acc: 0.9828\n",
      "Epoch 2/10\n",
      "5873/5873 [==============================] - 50s 9ms/step - loss: 2.7163e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "5873/5873 [==============================] - 49s 8ms/step - loss: 1.1840e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "5873/5873 [==============================] - 50s 9ms/step - loss: 1.1464e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "5873/5873 [==============================] - 50s 9ms/step - loss: 1.1057e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "5873/5873 [==============================] - 50s 9ms/step - loss: 1.1058e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "5873/5873 [==============================] - 51s 9ms/step - loss: 1.1586e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "5873/5873 [==============================] - 49s 8ms/step - loss: 1.0948e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "5873/5873 [==============================] - 51s 9ms/step - loss: 1.1142e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "5873/5873 [==============================] - 51s 9ms/step - loss: 1.0990e-07 - acc: 1.0000\n",
      "2518/2518 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "max_features = 3000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=20, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
